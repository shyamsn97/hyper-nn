{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install reqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install hyper-nn\n",
    "# !pip install gym\n",
    "# !pip install gym[box2d]\n",
    "# !pip install tqdm\n",
    "# !pip install tensorboard\n",
    "# !pip install matplotlib\n",
    "# !pip install celluloid\n",
    "# !pip install ipympl\n",
    "# !pip install JSAnimation\n",
    "# !pip install optax\n",
    "# !pip install tensorflow_probability\n",
    "# !pip install einops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shyam/anaconda3/envs/py39/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/shyam/anaconda3/envs/py39/lib/python3.9/site-packages/chex/_src/pytypes.py:37: FutureWarning: jax.tree_structure is deprecated, and will be removed in a future release. Use jax.tree_util.tree_structure instead.\n",
      "  PyTreeDef = type(jax.tree_structure(None))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'jax' has no attribute '_src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mjnp\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mflax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinen\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptax\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhypernn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m count_jax_params\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/optax/__init__.py:17\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 DeepMind Technologies Limited. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Optax: composable gradient processing and optimization, in JAX.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moptax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moptax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malias\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adabelief\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moptax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malias\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adafactor\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/optax/experimental/__init__.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2021 DeepMind Technologies Limited. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Experimental features in Optax.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mFeatures may be removed or modified at any time.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moptax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomplex_valued\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_real_and_imaginary\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moptax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomplex_valued\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SplitRealAndImaginaryState\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/optax/_src/experimental/complex_valued.py:32\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Complex-valued optimization.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mWhen using `split_real_and_imaginary` to wrap an optimizer, we split the complex\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03mSee details at https://github.com/deepmind/optax/issues/196\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NamedTuple, Union\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchex\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mjnp\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/chex/__init__.py:17\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 DeepMind Technologies Limited. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Chex: Testing made fun, in JAX!\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchex\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masserts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m assert_axis_dimension\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchex\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masserts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m assert_axis_dimension_comparator\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchex\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masserts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m assert_axis_dimension_gt\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/chex/_src/asserts.py:26\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01munittest\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munittest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mock\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchex\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m asserts_internal \u001b[38;5;28;01mas\u001b[39;00m _ai\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchex\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pytypes\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/chex/_src/asserts_internal.py:32\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Sequence, Union, Callable, Optional, Set, Tuple, Type\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabsl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchex\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pytypes\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mjnp\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/chex/_src/pytypes.py:44\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m Device \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mxla_extension\u001b[38;5;241m.\u001b[39mDevice\n\u001b[1;32m     42\u001b[0m ArrayTree \u001b[38;5;241m=\u001b[39m Union[Array, Iterable[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArrayTree\u001b[39m\u001b[38;5;124m'\u001b[39m], Mapping[Any, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArrayTree\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m---> 44\u001b[0m ArrayDType \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_src\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mlax_numpy\u001b[38;5;241m.\u001b[39m_ScalarMeta\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'jax' has no attribute '_src'"
     ]
    }
   ],
   "source": [
    "# uncomment this to enable jax gpu preallocation, might lead to memory issues\n",
    "\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "\n",
    "from typing import Sequence, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import optax\n",
    "import gym\n",
    "\n",
    "from hypernn.jax.utils import count_jax_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypernn.jax.hypernet import JaxHyperNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Policy Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(256, use_bias=False)(x)\n",
    "        x = nn.tanh(x)\n",
    "        x = nn.Dense(256, use_bias=False)(x)\n",
    "        x = nn.tanh(x)\n",
    "        x = nn.Dense(4, use_bias=False)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_network = MLP()\n",
    "\n",
    "count_jax_params(target_network, inputs=jnp.zeros((1,8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making a Lunar Lander Hypernetwork with a Custom Weight Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional, Tuple, Type, Union  # noqa\n",
    "import flax.linen as nn\n",
    "\n",
    "class LunarLanderHypernetwork(JaxHyperNetwork):\n",
    "\n",
    "    def make_weight_generator(self):\n",
    "        return nn.Sequential(\n",
    "            [\n",
    "                nn.Dense(32),\n",
    "                nn.tanh,\n",
    "                nn.Dense(self.weight_chunk_dim)\n",
    "            ]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can reduce the number of trainable parameters to less than 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6630"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 4\n",
    "NUM_EMBEDDINGS = 512\n",
    "\n",
    "hypernetwork = LunarLanderHypernetwork.from_target(\n",
    "    target_network = target_network,\n",
    "    embedding_dim = EMBEDDING_DIM,\n",
    "    num_embeddings = NUM_EMBEDDINGS,\n",
    "    inputs=jnp.zeros((1,8))\n",
    ")\n",
    "count_jax_params(hypernetwork, inputs=[jnp.zeros((1,8))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorboard utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "def get_tensorboard_logger(\n",
    "    experiment_name: str, base_log_path: str = \"tensorboard_logs\"\n",
    "):\n",
    "    log_path = \"{}/{}_{}\".format(base_log_path, experiment_name, datetime.now())\n",
    "    train_writer = SummaryWriter(log_path, flush_secs=10)\n",
    "    full_log_path = os.path.join(os.getcwd(), log_path)\n",
    "    print(\n",
    "        \"Follow tensorboard logs with: python -m tensorboard.main --logdir '{}'\".format(full_log_path)\n",
    "    )\n",
    "    return train_writer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rollout function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_probability.substrates import jax as tfp\n",
    "\n",
    "import jax\n",
    "import functools\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=('apply_fn', 'method'))\n",
    "def generate_params(apply_fn, hypernetwork_params, method):\n",
    "    generated_params, _ = apply_fn({'params':hypernetwork_params}, method=method)\n",
    "    return generated_params\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=('apply_fn'))\n",
    "def sample_actions(apply_fn, hypernetwork_params, obs, generated_params):\n",
    "    out =  apply_fn({'params':hypernetwork_params}, jnp.expand_dims(jnp.array(obs), 0), generated_params=generated_params, has_aux=False)\n",
    "    return out\n",
    "\n",
    "def rollout(env, apply_fn, generate_params_fn, hypernetwork_params, render=False, seed: int = 0, env_seed=None) -> float:\n",
    "    if env_seed is not None:\n",
    "        # env.seed(env_seed)\n",
    "        obs = env.reset(seed=env_seed)\n",
    "    else:\n",
    "        obs = env.reset()\n",
    "    done = False\n",
    "    observations, actions, rewards, rendereds = [], [], [], []\n",
    "    generated_params = generate_params(apply_fn, hypernetwork_params, generate_params_fn)\n",
    "    while not done:\n",
    "        rendered = None\n",
    "        if render:\n",
    "            rendered = env.render(mode=\"rgb_array\")\n",
    "            rendereds.append(rendered)\n",
    "\n",
    "        out = sample_actions(apply_fn, hypernetwork_params, obs, generated_params)\n",
    "        out = jnp.squeeze(out)\n",
    "        dist = tfp.distributions.Categorical(logits=out)\n",
    "        rng = jax.random.PRNGKey(np.random.randint(0, 10**10))\n",
    "        action = dist.sample(seed=rng).item()\n",
    "\n",
    "        next_obs, r, done, _ = env.step(action)\n",
    "\n",
    "        observations.append(obs)\n",
    "        actions.append(action)\n",
    "        rewards.append(r)\n",
    "\n",
    "        obs = next_obs\n",
    "\n",
    "    num_steps = len(observations)\n",
    "    env.close()\n",
    "    return observations, actions, rewards, rendereds, num_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reinforce algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "from flax.training import train_state  # Useful dataclass to keep train state\n",
    "import flax\n",
    "import logging\n",
    "\n",
    "# prevent a ton of warnings from https://github.com/tensorflow/probability/issues/1523\n",
    "logger = logging.getLogger(\"root\")\n",
    "\n",
    "\n",
    "class CheckTypesFilter(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        return \"check_types\" not in record.getMessage()\n",
    "\n",
    "\n",
    "logger.addFilter(CheckTypesFilter())\n",
    "\n",
    "def create_train_state(rng, hypernetwork, learning_rate, input_shape):\n",
    "    \"\"\"Creates initial `TrainState`.\"\"\"\n",
    "    params = hypernetwork.init(rng, [jnp.zeros(input_shape)])['params']\n",
    "\n",
    "    tx = optax.chain(\n",
    "        optax.clip_by_global_norm(100.0),\n",
    "        # optax.scale_by_adam(),  # Use the updates from adam.\n",
    "        # optax.scale_by_schedule(scheduler),  # Use the learning rate from the scheduler.\n",
    "        # # Scale updates by -1 since optax.apply_updates is additive and we want to descend on the loss.\n",
    "        # optax.scale(-1.0)\n",
    "        optax.adam(learning_rate)\n",
    "    )\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=hypernetwork.apply, params=params, tx=tx)\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=('apply_fn'))\n",
    "def train_step(apply_fn, state, observations, actions, discounted_rewards):\n",
    "    def loss_fn(params):\n",
    "        logits = apply_fn({'params':params}, observations, has_aux=False)\n",
    "        dist = tfp.distributions.Categorical(logits=jnp.squeeze(logits))\n",
    "        log_probs = jnp.squeeze(dist.log_prob(actions))\n",
    "        loss = jnp.sum(discounted_rewards * log_probs)\n",
    "        return -1*loss\n",
    "    grad_fn = jax.value_and_grad(loss_fn)\n",
    "    loss, grads = grad_fn(state.params)\n",
    "    return state.apply_gradients(grads=grads), loss, grads\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import collections\n",
    "\n",
    "def flatten(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, flax.core.frozen_dict.FrozenDict) or isinstance(v, dict):\n",
    "            items.extend(flatten(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "def discount_reward(rews, gamma: float = 0.99):\n",
    "    n = len(rews)\n",
    "    rtgs = np.zeros_like(rews)\n",
    "    for i in reversed(range(n)):\n",
    "        rtgs[i] = rews[i] + gamma*(rtgs[i + 1] if i + 1 < n else 0)\n",
    "    return rtgs\n",
    "\n",
    "def reinforce(\n",
    "        num_epochs,\n",
    "        env,\n",
    "        hypernetwork,\n",
    "        env_seed: int = None,\n",
    "        seed: int = 0,\n",
    "        lr: float = 0.0001,\n",
    "        gamma: float = 0.99,\n",
    "    ):\n",
    "    writer = get_tensorboard_logger(\"HypernetworkJaxRL\")\n",
    "\n",
    "    rng = jax.random.PRNGKey(seed)\n",
    "    rng, init_rng = jax.random.split(rng)\n",
    "    state = create_train_state(init_rng, hypernetwork, lr, (1,8))\n",
    "\n",
    "    bar = tqdm.tqdm(np.arange(num_epochs))\n",
    "\n",
    "    try:\n",
    "        for i in bar:\n",
    "            observations, actions, rewards, _, num_steps = rollout(env, hypernetwork.apply, hypernetwork.generate_params, state.params, seed=seed, env_seed=env_seed)\n",
    "            discounted_rewards = discount_reward(np.array(rewards), 0.99)\n",
    "            discounted_rewards = discounted_rewards - np.mean(discounted_rewards)\n",
    "            discounted_rewards = discounted_rewards / (\n",
    "                np.std(discounted_rewards) + 1e-10\n",
    "            )\n",
    "\n",
    "            observations = jnp.array(observations)\n",
    "            actions = jnp.array(actions)\n",
    "            discounted_rewards = jnp.array(discounted_rewards)\n",
    "\n",
    "            state, loss, grads = train_step(hypernetwork.apply, state, observations, actions, discounted_rewards)\n",
    "            grad_dict = {k:dict(grads[k]) for k in grads.keys()}\n",
    "            grad_dict = flatten(grad_dict)\n",
    "            grad_dict = {k:np.sum(np.array(grad_dict[k])) for k in grad_dict}\n",
    "\n",
    "            metrics = {\"loss\":loss.item(), \"rewards\":np.sum(rewards), \"num_steps\":num_steps, **grad_dict}\n",
    "\n",
    "            for key in metrics:\n",
    "                writer.add_scalar(key, metrics[key], i)\n",
    "\n",
    "            bar.set_description('Loss: {}, Sum Reward: {}'.format(loss.item(), np.sum(rewards)))\n",
    "        return hypernetwork, state\n",
    "    except KeyboardInterrupt as e:\n",
    "        return hypernetwork, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"LunarLander-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Follow tensorboard logs with: python -m tensorboard.main --logdir '/home/shyam/Code/hyper-nn/notebooks/reinforce/tensorboard_logs/HypernetworkJaxRL_2022-11-01 16:21:42.146957'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/5000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'jax' has no attribute 'named_scope'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hyper, state \u001b[38;5;241m=\u001b[39m \u001b[43mreinforce\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypernetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0002\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mreinforce\u001b[0;34m(num_epochs, env, hypernetwork, env_seed, seed, lr, gamma)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m bar:\n\u001b[0;32m---> 84\u001b[0m         observations, actions, rewards, _, num_steps \u001b[38;5;241m=\u001b[39m \u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypernetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypernetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m         discounted_rewards \u001b[38;5;241m=\u001b[39m discount_reward(np\u001b[38;5;241m.\u001b[39marray(rewards), \u001b[38;5;241m0.99\u001b[39m)\n\u001b[1;32m     86\u001b[0m         discounted_rewards \u001b[38;5;241m=\u001b[39m discounted_rewards \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(discounted_rewards)\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mrollout\u001b[0;34m(env, apply_fn, generate_params_fn, hypernetwork_params, render, seed, env_seed)\u001b[0m\n\u001b[1;32m     31\u001b[0m out \u001b[38;5;241m=\u001b[39m sample_actions(apply_fn, hypernetwork_params, obs, generated_params)\n\u001b[1;32m     32\u001b[0m out \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39msqueeze(out)\n\u001b[0;32m---> 33\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[43mtfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m rng \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mPRNGKey(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m     35\u001b[0m action \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39msample(seed\u001b[38;5;241m=\u001b[39mrng)\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m<decorator-gen-193>:2\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, logits, probs, dtype, validate_args, allow_nan_stats, name)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/distributions/distribution.py:342\u001b[0m, in \u001b[0;36m_DistributionMeta.__new__.<locals>.wrapped_init\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# Note: if we ever want to have things set in `self` before `__init__` is\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;66;03m# called, here is the place to do it.\u001b[39;00m\n\u001b[1;32m    341\u001b[0m self_\u001b[38;5;241m.\u001b[39m_parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m \u001b[43mdefault_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;66;03m# Note: if we ever want to override things set in `self` by subclass\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# `__init__`, here is the place to do it.\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m self_\u001b[38;5;241m.\u001b[39m_parameters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    346\u001b[0m   \u001b[38;5;66;03m# We prefer subclasses will set `parameters = dict(locals())` because\u001b[39;00m\n\u001b[1;32m    347\u001b[0m   \u001b[38;5;66;03m# this has nearly zero overhead. However, failing to do this, we will\u001b[39;00m\n\u001b[1;32m    348\u001b[0m   \u001b[38;5;66;03m# resolve the input arguments dynamically and only when needed.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/distributions/categorical.py:189\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[0;34m(self, logits, probs, dtype, validate_args, allow_nan_stats, name)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (probs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m (logits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    188\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMust pass probs or logits, but not both.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname_scope\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m name:\n\u001b[1;32m    190\u001b[0m   prob_logit_dtype \u001b[38;5;241m=\u001b[39m dtype_util\u001b[38;5;241m.\u001b[39mcommon_dtype([probs, logits], tf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    191\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probs \u001b[38;5;241m=\u001b[39m tensor_util\u001b[38;5;241m.\u001b[39mconvert_nonref_to_tensor(\n\u001b[1;32m    192\u001b[0m       probs, dtype_hint\u001b[38;5;241m=\u001b[39mprob_logit_dtype, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprobs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/tensorflow_probability/python/internal/backend/jax/ops.py:527\u001b[0m, in \u001b[0;36mname_scope.__init__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m JAX_MODE \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 527\u001b[0m   jax_named_scope \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamed_scope\u001b[49m(name)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m   jax_named_scope \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'jax' has no attribute 'named_scope'"
     ]
    }
   ],
   "source": [
    "hyper, state = reinforce(5000, env, hypernetwork, seed=0, lr=0.0002, env_seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib ipympl\n",
    "# Imports specifically so we can render outputs in Jupyter.\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "from celluloid import Camera\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "def render_rollout(model, state, seed=10):\n",
    "    fig = plt.figure()\n",
    "    camera = Camera(fig)\n",
    "    ax = fig.add_subplot(111)\n",
    "    observations, actions, rewards, rendereds, num_steps = rollout(gym.make(\"LunarLander-v2\"), model.apply, model.generate_params, state.params, seed=seed, render=True)\n",
    "    frames = []\n",
    "    for r in rendereds:\n",
    "        frame = ax.imshow(r)\n",
    "        ax.axis('off')\n",
    "        camera.snap()\n",
    "        frames.append([frame])\n",
    "    print(\"Sum Reward: {}\".format(np.sum(rewards)))\n",
    "    animation = camera.animate(interval=50)\n",
    "    # display(animations.to_html5_video())\n",
    "    animation.save('HyperJaxLunarLander.mp4')\n",
    "    return animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shyam/anaconda3/envs/test_hyper_nn/lib/python3.9/site-packages/ipywidgets/widgets/widget.py:477: DeprecationWarning: Passing unrecognized arguments to super(Toolbar).__init__().\n",
      "__init__() missing 1 required positional argument: 'canvas'\n",
      "This is deprecated in traitlets 4.2.This error will be raised in a future release of traitlets.\n",
      "  super(Widget, self).__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum Reward: 260.24496438338485\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2177b7982fa4f21afb59a8104b2bdd9",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "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",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAj30lEQVR4nO3de5DddX3/8dc5e83mfieEhEAIl0LCTTC1EEsVAgUDiWinBJ2ft9rWSq2t6LTWwZnWzljrTKe2M51pf46jVRFraaAB5SLhKiAQyIVLLuRC7mzul81uds/vj/0lgvUCJJuzyefxmDmzye7mfN/JZnef+/neKrVarRYAAIpRrfcAAAAcXQIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMI31HuBYV6lU6j0CAPAm1Wq1eo9QV1YAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAK01jvAYDjz1/+ZXLVVcmuXcnzzyd33JEsWpTUasmBA0lHR9LZWe8py3D11cnnPpfs25e8/HLyox8lDzzQ+7Ho7k727+/9eABlEYDAEdfYmAwY0PsYMyZ55zt7g2PfvmTNmuShh5JnnukNkH37ki1beh8ceQ0NP/tYjBiRXHhhbxDu359s2pQ88UTy4x8nPT29IbhtW7JuXb2nBvqaAASOikolaWtLzjyz91GrJV1dydatydKlyZIlvUG4Y0eyalXviiF9o1JJWluTk0/ufVx/fe/K7I4dycqVvVHY3Z3s3p288kpvrB84UO+pgSNJAAJ1Uakkzc3JCSf0Pi67rHcVau/e3pWp1at7o6O9vTcQ77mnN0o48iqVpKkpGTWq93HRRT9bsW1v743Czs5k587kpZeSe+/t/TVw7BKAQL9QqfTurhw8uPcxefLPjhncty/5vd9LPvShek9Zhkql9zFwYO9jwoTe1x88fvMDH0huvDHZs6e+cwJvnQAE+oVa7WcnJuzb13sCSVfXz45T++536z1hOWq13pfd3b3Bd/Bj0d6eLFyY3Hab+INjnQAE6uJg7O3dm2zcmKxf3xsZW7b0Rsb999d7wnLUar273/ftS1599We737du7T2L++67nbUNxxsBCBwVtVpvRGzZ0nvCx4oVvZGxbVvvcWUvvljvCctxcNf6wX/7557rjfGdO3tPwHnmmXpPCPQ1AQj0iYMndKxcmSxY0BsaB88s3bixd3WJo6NW692Vu25d8uijyZNP/mzFb8uWZMOGek8IHG0CkONCtVpNY2Njenp60t3dndrBg5ioi5NO+kpuvvnfs3jx8+nq6g3Brq56T1Wm4cN/L9/5TlO++c1vpaurNwRd+BlwKziOaYMHD87ZZ5+dz3/+89mwYUP+4z/+I9ddd10mTpyYgQMH1nu8YjU2jsi2bc159dXea8uJv/qpVtuyZ8/AbNmSbN8u/oBeVgA5Jo0ePTrnnXderrzyysyZMyeTJk1Kkrz//e/P7Nmzs3Tp0syfPz+PPPJInn/++axevTrdLiIHAEkEIMeYMWPG5Kqrrsrll1+eGTNmZMLBC5S9RlNTU84999yce+652bJlS55++uk8+eSTeeihh/Loo49m9+7ddZic/mjIkBMyevTk//+7X33YwOuPKvj1hxhUKtV0du7Npk0vprNz71ueEaAvCECOCYMHD87HPvaxvPe9782UKVMycuTIVKu//giG0aNHZ+bMmfnt3/7t3HjjjVmzZk3mz5+f//zP/8zy5cuPwuT0Z6NGnJrfPO9jGdR8Qiqp/oqu++XBV/slbzvQ05EVGx7Itm1rBSDQ7whA+q3GxsaMGzcuH/jAB/KJT3wiw4cPT2trayqVypt+rpaWlkyaNCknn3xyLr744vzZn/1ZHn300fz7v/97HnnkkezevTsH3Oy0KONHn5/fufjmtDYPzcgBU47483f17EutUsvyFQ9m9+5Xj/jzAxwOAUi/M2zYsJx66qm5/vrr88EPfjAnnnhikryl8Pt5lUolra2taWlpyXXXXZfrrrsuy5cvz6233prbb78969evz6uvvpouZy0c/yq1NDQ0p6k6IEnliPz/eq3GSksaq83piR8sgP5HANJvjB07NhdffHGuuuqqXHvttYfCry+89pv9lClT8vnPfz6f+tSn8sADD+T+++/P008/ncWLF6e9vb3PZqC+umtdqaU7DdW3tqr861SrjWmoNqWhoTFJJW/kuEGAo0UAUndjx47N7NmzM3PmzEyfPj1jxox5Q8f3HWmDBg3KNddck5kzZ2blypVZuHBhHnvssdx333154YUX7CI+zvTUulKrdaex2tpn22iqtmXI4HFpaFiU7m6rykD/IQCpm/Hjx+fGG2/M7//+72fixIkZPnx4vUdK0nsW8RlnnJHTTz89V155Zf74j/84Tz/9dL7//e/nBz/4gYtMHweamwbl6ku+lJ5adxqrLX22naZqW6ZNmZNVq57I7r1b+mw7AG+WAOSoamlpyYknnpgPf/jD+cAHPpBx48alqampT3bBHa5KpZKhQ4dm6NChmTx5cq699tr80z/9U77+9a/nu9/9blauXJmOjg7XFzwGVSsNGT5kYnZ2rktDpbnPttPU0JbW1iGpVPvf/2+gbAKQPlepVDJixIiccsopmTt3bubOnZvRo0fXe6w3paGhIQMGDMiAAQPyl3/5l/nUpz6Vhx56KLfeemuefPLJrFu3Ltu3b7c6eIyopSedPbvT3DCoT3/4aKwOSHdP5y+9VAxAvQhA+kylUsn48eNzySWX5IorrsisWbMyYsSIfrna92a1tbVl5syZueKKK7Js2bI88MADeeyxxw6dPNLT01PvEfmVauns3pO2plF9upWGalMaqk1pbR2c3bvtAgb6DwFInzj55JMzZ86cXHXVVTn33HMzZsyYeo/UJyqVSk4//fScfvrpef/735+XXnopixcvzt13350FCxZk8+bN9R6RX6BW60ln9+4Maz2lz7fV0jAkQ4ecmFdfXdnn2wJ4owQgR9RJJ52Uj370o5k9e3YmTZqUIUOG1Huko2bYsGG5+OKLc+GFF+aaa67J2rVrc8899+Rb3/pWli5davdwPzL3qm9lf/fWtDQM6vNttTQOzdvOuTErX340tZqVYaB/EIAclkqlkgEDBmT48OH5i7/4i8ydOzfDhw9PQ0PDcbGr961oaGjImDFjMnr06Jx77rmH7jry9a9/Pffee2927NiRffv2CcI6GjL4hGzbvzvVSlOfb6ulcWgaG/t+OwBvhgDkLalUKhk7dmzOOeeczJ49Ox/+8IfT2tp311M7FlUqlTQ2NqaxsTGXXXZZLrvssqxduzb//d//nfnz52fZsmVZt25d9u3bV+9Ri7PvwNa0Ng07Kj+ktDQMSlfPnlSrDenutgII9A8CkDdt0qRJueyyy3LFFVfkd37nd47b4/v6woQJE/Inf/In+ehHP5rHH388jzzySB5//PE88cQT2bRpk1XBo2TX/vUZMfDUo7KtaqUx1WpThg07Ke3tLx+VbQL8OgKQN+yUU07JDTfckHe/+92ZNm1aRowYUe+Rjlmtra155zvfmXe84x3ZuHFjli9fnkceeSTz5s3Lk08+We/xjntdPfvSVG07attrqraltXXwL3mr28QBR58A5Fc6uKv3z//8zzNnzpyMHTs2bW1txR7fd6Q1NTVlwoQJmTBhQqZPn56PfOQjefnllzNv3rzMmzcvy5YtS3d3t5XBt2jq1GtSrTZk1aonsmPHxhwMrcZKS6rVvrsA9M9rrLSkq+vgrv5KKpVk9OjTcvLJF2Xt2qezceMLR20WgEQA8gtUKpUMHjw4U6ZMyYc+9KF89KMfPXS3DuHXdw5eaPqEE07I29/+9vzN3/xNFi9enHnz5uWHP/xhVq5cmd27d2f37t31HvWY0DZgRMaMPD0j2k7L+NHnprNnd5a+8KNs2LAkvatudZipbUTOPP1dOXHcORnYNDYDmodn+/ZXBGAB2traMmTIkDQ1NR36PO7qcn9o6kcA8jonnXRSzj///MyePTuzZs3KyJEj6z1ScSqVShoaGpIk5513Xs4777x89rOfzdKlS/PAAw/kwQcfzJo1a7J27dq0t7e76PQvcfbpV+e0ce/O2EHnpLunMy9uvCsHDnTWdTV15JBTc+akmRkz5OwMbZmYzu5dGTvqrKxe/dN0du6t21z0jdbW1kyaNCmTJk3KjBkzcuWVV2bixIlZsGBBFixYkEWLFmXNmjVZv369k8E46gQgSZLJkydn5syZufzyy3PppZcKv36mpaUl559/fs4///zcdNNNWbJkSRYtWpTnnnsuzz77bJ599tls3Lix3mP2G6OGnZbRIyenrWlUKmlIV/ferNn0k+zYsb6uc+3ctSFbt67NkLaTMrj5QBqqLTlx5HkZMuQeF4o+jpx++umHrgl6wQUX5IILLsigQT+75uScOXMyZ86cbNiwIYsWLcrixYsPfR4/99xzDvngqBCAhWtubs773ve+/Omf/mnOOOOMDB482G7efq6hoSHTpk3LtGnTMnv27GzatCmvvPJKFi1alPvvvz/33Xdftm/fXu8x62rokBMzfswFaWnsPfFi1/6N2bZjbfbvr+/u8117N2br1tUZMXJCRg6YksZqS8YMPTMjhp+c9vbVqdW66zofb92wYcPyu7/7u7nqqqty1llnZcKECb/2Cgnjxo3LuHHj8q53vSvbtm3L+vXrs3bt2vz4xz/O/fffnyVLlqSzs/Mo/Q0ojQAsWEtLSz75yU/mr//6r4u6Y8fxpK2tLaecckomTZqU6dOnZ+7cudm7d28eeuih/OAHP8j999+fbdu2paenp6hdxV09e1KtNKa5YWBqte68vGnBz62w1VI5iscBHlzP6al1Z92mZzNu/FnZM3hLhrZMSFvzqIwfc27WrH0qHR07j9pMHJ6GhoY0NDRkxowZmTt3bmbOnJmBAwdm4MCBhw7heDPPNWrUqIwaNSpTp07NZZddls997nNZsWJF7r777tx+++1ZunRpuru7093thwSODAFYqLFjx+aWW27Jxz/+cSt+x4FKpZKmpqYMHTo0Q4cOzfve975cf/312blzZx588MHceeedefjhh9Pe3p4dO3Zk//799R65zwwbPCG/O+Nv0to4tHf3b8+e7Nj3SrZte+XQ+/SkO109e9JxYMdhb++NhGR3rTOVSjVJsm7LM5m277ps27c8Q1smpKVhSE4ae34Gto0QgP1cW1tbRowYkQkTJhz6HBs/fvwRPUGuUqmkra0tbW1tGTlyZC6++OL81V/9VZYtW5Y777wzd9xxR1avXp0dO3Zk165dRf1gx5ElAAtzcPfhF7/4xVx11VXi7zh18BvSsGHDMmvWrMyaNSvbtm3Lo48+mocffjjPPfdcVq1alVWrVmXv3uPp5INKJk+4NPu7d2ZE6+RUKpVs2PVs1q1b9Lr3aqg0ZXvHmuzcvy6He0bwr/7TvW/trnW+LhRXrflJWocMSNeQvWluGJhhbZNywpizsnXbWruB+5mmpqacdtppOe200/L2t7897373u3PxxRcfla+dB7fR2NiYs846K2eddVY+85nPZPHixXnwwQfz+OOPZ9myZVm1alU2btzo2EHeFAFYkObm5lx55ZX5whe+kPPOO+9N76bg2DZ8+PBcffXVufrqq/Pqq6/m+eefz9KlS/PMM8/kqaeeytKlS4/5GKxWG3LJhX+SPV2b0tQwMN09Xdmy6/ls3Pji697v+RfuS2O1+f+vytUO8zLMv/5Pd/d0ZctrdkGvXP9wzv6Nq7N13/KcMOjcDGo+ISdPuCgvLr8/Bw4IwP7g1FNPzTve8Y5Mnz49U6dOzbRp0zJs2LB6j5UkOeecc3LOOefkwx/+cF5++eU8//zzWbx4cX7605/mqaeeyvr19T3ZiWODACxEpVLJxz72sdx8882ZOHFivcehzkaNGpVLL700l1xySbZv357NmzdnzZo1efjhh3P33XfniSeeqPeIb02tlh0dqzOybUoqlUp279+QDZuWpLNzz+vebeELt9ZpwF77O3dlzdqn0tTalDEDz05zw6CMHf4bGT58QrZsWV7X2UrW2tqaWbNm5T3veU+mTp2acePGZfTo0f12T0lra+uhlcGrr746mzdvzubNm7No0aLcc889ueeee7Jly5Z6j0k/JQAL0NLSkr/7u7/Lxz/+8bS1Hb3bX9H/VSqVDB8+PMOHD8+UKVMyY8aMfPrTn86mTZty++2357/+67+yZMmSdHR05MCBA/1+F9P/mfWf2dezKYOaT0itVsvm3Uuzas3j9R7rF1r4wq35jTNnZnfnxgxpOSnDWydn4oQLBeBR1NTUlKamplx00UW54YYbMmfOnAwYMCAtLS1pbDy2vj22tLQcuqvQueeem/e9733Zu3dvHnnkkdx+++2577778uqrr6arq8uJJCQRgMe1hoaGTJgwIV/5ylcya9asNDU11Xsk+rFqtZqWlpa0tLRkyJAh+cxnPpPPfOYzWbFiRebPn5977703L774Ytrb27N169Z+F4PDh5yczsr2DG89NZVKNR0HdmT7rrXZuXNTvUf7hboO7M8r6xamaWJrBjefmMEtJ2b8CdPyXNO819w2jiNt4MCBGTVqVE488cTMnj07c+bMyamnnpok/Xal781qbGxMY2Nj2tracu211+baa6/N7t278+ijj+bOO+/MQw89dOjz+Fg/7IO3TgAepxobGzNjxox84QtfyDvf+c56j8Mx5rXfCE877bTcdNNN+aM/+qOsWLEiP/nJT/KTn/wkL730UpYvX54NGzbkwIEDdZy217su/my6KnvT2jgsPbXu7Nq/PitWP5QDB/rnddRqte4sXT4/40+cms7uPWmstmZ426ScfPKFWb784XqPd1ypVqs544wzcuaZZ+Ztb3tbZsyYkXe84x2pVqv1Hq1PvfbzePDgwZk5c2ZmzpyZXbt2Hfo8fu655/LSSy/l5Zdfzq5du+o4LUebADxO3Xjjjfn0pz+dqVOn1nsUjhNNTU0588wzc+aZZ+aDH/xgVq5cmWXLlmXJkiV58skn88QTT2TVqlV1m6+WngxpmZid+9dlR8ea7OpYn1fbV/Trs2p37FqXLVtXpFptTLXSmEqqOXDg+L1Ez9E2ceLEQ8e6nnPOOTnzzDMzatSoeo9Vd4MHD87ll1+eyy+/PFu3bs2yZcvy4osvZuHChXn88cfzxBNP9Isf6uhblVp/249zjOmPuwxuueWW/OEf/mHGjh1b71EowP79+7N9+/Zs2bIlS5cuzV133ZUXXnghzz777FG9v+mIIZNy0tgLMn7seRk9cnLWbXsmj/30/2bv3q1HbYY3q1JpyJRTZ2TaWbOzft3iLF+zIO3bV6a7u+uIbWPUqFGpVCrFnAxQrVYza9asXHfddXnb296W0aNH9+sTOfqLnp6e7N69O+3t7dmyZUt+9KMf5a677srTTz+djo6Oeo/XJ0rPHwF4mPrLF5VKpZIxY8bkq1/9at773vemubm538xGGWq1Wnp6enLgwIF0dXXV5QK11UpDqtXGVCrV1Grd6e7p6vdf5KvVhjRUm9LT053ungN5I5eVebM6Ojqybdu2Q8d9HXy89nXbtm173dsOfjzf6Mt6OXjc6tSpU3PDDTfk/e9/fwYNGpSmpiaXunqLarXaoc/jV1555dDdSJ5++uns378/nZ2dx8UFqPv714a+JgAPU3+IrGq1mvPPPz9f/OIXc/XVV9d7HOAY19PTkx07dmTHjh3Zvn37ocfB3//867dv356Ojo50dXUdehwMiF/2OJwzUdva2nLCCSdk3Lhxueaaa/Ke97wnZ5999hH8F+Dn9fT0ZM2aNfnRj36UH/7wh1myZElWrVp1TN9VqPT8EYCHqT8E4LXXXpvPfe5zmT59er1HAQrV0dGR3bt3Z8+ePa97+ct+vWfPnuzbt+91j46Ojv/1utc+zjjjjEydOjXnn39+fuu3fivTp09Pc3Nzvf/qRfrpT3+aefPmZcGCBVm4cGF27jz2bmNYev4IwMNUzwBsaGjITTfdlJtuuimTJk2q2xwAb1Z3d3f279+f/fv3p6Oj43/9+udf7t+/P5MmTcqUKVMyZsyYeo9Pej+GL730Uh5//PHccccdmT9//jF1vGDp+SMAD1O9AnDkyJG55ZZb8sEPfjCDBw/uFyuRAJSnq6sr27Zty4oVK/LP//zPue2229LZ2T8vv/RapeePADxM9QivyZMn52//9m9z/fXXO8gZgH7h4Mkjq1evzj/+4z9m3rx52bx5c79dFSw9fwTgYTraATh9+vR8+ctfzqWXXnpUtwsAb8ZLL72Ub3/727nrrruyYsWKfncHof40Sz0IwMN0tAJwwIABee9735svfOELOe200+zyBaDfq9VqWb16de67777cd999uffee/vNNSlLzx8BeJiORoiNHDkyn/zkJ/OJT3wiI0eOFH8AHFN6enqyefPmLFmyJHfccUduu+22rF+/vq4zlZ4/AvAw9XWMjRo1Kl/60pdyww03ZODAgX26LQDoa7t27cratWvzve99L7fffnteeOGFulxPsPT8EYCHqa8CsFKpZMKECfnmN7+ZSy655Li/aTkA5ajVaqnVamlvb893vvOd/Mu//Es2bNiQXbt2HbUwKz1/BOBh6osAHDBgQC655JJ87Wtfy5QpU+zyBeC4VavV0tHRkW9/+9uZN29eFi5cmFdeeaXPbzdXev4IwMN0pONs+PDhufHGG/PZz34248ePP6LPDQD9WXt7ex599NHcf//9ueeee7Jy5crs27evT7ZVev4IwMN0JANwyJAhueWWW3LjjTdm9OjRR+x5AeBYsnPnzixbtiyPPfZY/vVf/zVLliw54sFWev4IwMN0pAKwtbU18+bNy6WXXprW1tYj8pwAcKyq1Wrp6urKzp07c/fdd+erX/1qFi9enAMHDhyReCs9fwTgYTrcAGxubs55552X7373u5k0aZLj/QDg59RqtfT09OTOO+/MrbfemmeffTbLly8/rFvOlZ4/AvAwHU6wDRo0KLNnzz50cWcA4Ffbs2dPHnnkkcyfPz8PPPBAlixZkgMHDrzp5yk9fwTgYXqrAThgwIDcfPPN+chHPpIJEyYc4akA4PjW2dmZZ555JgsWLMj8+fOzZs2abNiw4Q3fe7j0/BGAh+mtBODAgQPzjW98I5dffnmGDBnSB1MBQBm6urqyZs2aLFmyJP/2b/+WhQsXZu3atb/2z5WePwLwML2ZAKxWqzn77LPzjW98I9OmTUtDQ0MfTgYA5eju7s6+ffuydOnSfOUrX8kPf/jD7NmzJ5VK5RfuIi49fwTgYXqjAdjS0pIrrrgiX/rSl3L22Wc72QMA+sDBu4wsWbIkX/va19LT05Pvfe976erqet01BUvPHwF4mN5IyDU2NuYP/uAP8ulPfzqTJ08+ClMBAEny3HPP5Y477sjzzz+fe+65J+3t7enu7haAAvDw/LoAHDVqVG655ZbMnTs3w4YNOzpDAQCHdHd35+WXX85TTz2V//mf/8n3v//97N27t95j1ZUAPEy/KgDPOuusfPnLX86VV16ZxsbGozgVAPDzuru7097enldeeSUXXHBBvcepKwF4mH5RAFar1fzmb/5m/uEf/iEXXXRRqtVqHSYDAPjFLEsdYc3Nzbnmmmvy93//9zn11FPrPQ4AwP8iAI+gMWPG5EMf+lA+//nPZ9CgQfUeBwDgFxKAR8gZZ5yRm2++OXPnzk1LS0u9xwEA+KUE4BFwzjnn5Ktf/WpmzJgh/gCAfk8AHqYLL7wwt912W04++WQnewAAxwRnAQMAFMaSFQBAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGH+H7PQxXnflrfdAAAAAElFTkSuQmCC' width=640.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vid = render_rollout(hypernetwork, state, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Play video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"HyperJaxLunarLander.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"HyperJaxLunarLander.mp4\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d64cb66d3d902aa83000daa06ca958bef94bde318911a82aee5f8df2bb8934b"
  },
  "kernelspec": {
   "display_name": "Python [conda env:py39] *",
   "language": "python",
   "name": "conda-env-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
