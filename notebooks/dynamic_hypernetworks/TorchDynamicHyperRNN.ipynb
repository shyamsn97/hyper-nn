{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tutorial adapted from https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install reqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install hyper-nn\n",
    "# !pip install tqdm\n",
    "# !pip install tensorboard\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# categories: 18 ['Portuguese', 'Czech', 'Korean', 'Arabic', 'English', 'Russian', 'German', 'Spanish', 'Vietnamese', 'Polish', 'Irish', 'Japanese', 'French', 'Scottish', 'Greek', 'Chinese', 'Italian', 'Dutch']\n",
      "O'Neal\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "n_letters = len(all_letters) + 1 # Plus EOS marker\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    with open(filename, encoding='utf-8') as some_file:\n",
    "        return [unicodeToAscii(line.strip()) for line in some_file]\n",
    "\n",
    "# Build the category_lines dictionary, a list of lines per category\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "for filename in findFiles('./names/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "if n_categories == 0:\n",
    "    raise RuntimeError('Data not found. Make sure that you downloaded data '\n",
    "        'from https://download.pytorch.org/tutorial/data.zip and extract it to '\n",
    "        'the current directory.')\n",
    "\n",
    "print('# categories:', n_categories, all_categories)\n",
    "print(unicodeToAscii(\"O'Néàl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TargetRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(TargetRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.rnn = nn.GRUCell(n_categories + input_size, self.hidden_size)\n",
    "        self.linear = nn.Linear(self.hidden_size, 256)\n",
    "        self.linear2 = nn.Linear(256, 256)\n",
    "        self.linear3 = nn.Linear(256, self.output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, category, inp, hidden):\n",
    "        concatenated = torch.cat((category, inp), dim=-1)\n",
    "        hidden =  self.rnn(concatenated, hidden)\n",
    "\n",
    "        output = self.linear(hidden)\n",
    "        output = torch.relu(output)\n",
    "        output = self.linear2(output)\n",
    "        output = torch.relu(output)\n",
    "        output = self.linear3(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193467"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_network = TargetRNN(n_letters, 128, n_letters)\n",
    "pytorch_total_params = sum(p.numel() for p in target_network.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic Hypernetwork that modifies its weights based on network inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from typing import Optional, Iterable, Dict, Any, Tuple\n",
    "from hypernn.torch.dynamic_hypernet import TorchDynamicHyperNetwork\n",
    "\n",
    "class CharDynamicHyperNetwork(TorchDynamicHyperNetwork):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        target_network: nn.Module,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(\n",
    "            input_dim,\n",
    "            target_network,\n",
    "            *args,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def generate_params(\n",
    "        self, category_tensor, input_tensor, hidden_state: Optional[torch.Tensor] = None\n",
    "    ) -> Tuple[torch.Tensor, Dict[str, Any]]:\n",
    "        concatenated = torch.cat((category_tensor, input_tensor), dim=-1)\n",
    "        embedding, hidden_state = self.embedding_module(concatenated, hidden_state=hidden_state)\n",
    "        generated_params = self.weight_generator(embedding).view(-1)\n",
    "        return generated_params, {\"embedding\": embedding, \"hidden_state\": hidden_state}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24523"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 4\n",
    "NUM_EMBEDDINGS = 64\n",
    "\n",
    "\n",
    "hypernetwork = CharDynamicHyperNetwork.from_target(\n",
    "    target_network,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    num_embeddings=NUM_EMBEDDINGS,\n",
    "    input_dim=n_letters+n_categories\n",
    ")\n",
    "pytorch_total_params = sum(p.numel() for p in hypernetwork.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "hypernetwork = hypernetwork.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Random item from a list\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "# Get a random category and random line from that category\n",
    "def randomTrainingPair():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    return category, line\n",
    "\n",
    "# One-hot vector for category\n",
    "def categoryTensor(category):\n",
    "    li = all_categories.index(category)\n",
    "    tensor = torch.zeros(1, n_categories)\n",
    "    tensor[0][li] = 1\n",
    "    return tensor\n",
    "\n",
    "# One-hot matrix of first to last letters (not including EOS) for input\n",
    "def inputTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li in range(len(line)):\n",
    "        letter = line[li]\n",
    "        tensor[li][0][all_letters.find(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# LongTensor of second letter to end (EOS) for target\n",
    "def targetTensor(line):\n",
    "    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n",
    "    letter_indexes.append(n_letters - 1) # EOS\n",
    "    return torch.LongTensor(letter_indexes)\n",
    "\n",
    "# Make category, input, and target tensors from a random category, line pair\n",
    "def randomTrainingExample():\n",
    "    category, line = randomTrainingPair()\n",
    "    category_tensor = categoryTensor(category)\n",
    "    input_line_tensor = inputTensor(line)\n",
    "    target_line_tensor = targetTensor(line)\n",
    "    return category_tensor, input_line_tensor, target_line_tensor\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "def get_tensorboard_logger(\n",
    "    experiment_name: str, base_log_path: str = \"tensorboard_logs\"\n",
    "):\n",
    "    log_path = \"{}/{}_{}\".format(base_log_path, experiment_name, datetime.now())\n",
    "    train_writer = SummaryWriter(log_path, flush_secs=10)\n",
    "    full_log_path = os.path.join(os.getcwd(), log_path)\n",
    "    print(\n",
    "        \"Follow tensorboard logs with: python -m tensorboard.main --logdir '{}'\".format(full_log_path)\n",
    "    )\n",
    "    return train_writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def train_dynamic_hyper_rnn_step(dynamic_hyper_rnn, optimizer, category_tensor, input_line_tensor, target_line_tensor):\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    target_line_tensor = target_line_tensor.unsqueeze(-1).to(dynamic_hyper_rnn.device)\n",
    "    hidden = target_network.initHidden().to(dynamic_hyper_rnn.device)\n",
    "    hyper_hidden = dynamic_hyper_rnn.embedding_module.init_hidden()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(input_line_tensor.size(0)):\n",
    "        out, _, aux_output = dynamic_hyper_rnn(\n",
    "            category_tensor.to(dynamic_hyper_rnn.device),\n",
    "            input_line_tensor[i].to(dynamic_hyper_rnn.device),\n",
    "            hidden,\n",
    "            generate_params_kwargs={\n",
    "                \"category_tensor\":category_tensor.to(dynamic_hyper_rnn.device),\n",
    "                \"input_tensor\":input_line_tensor[i].to(dynamic_hyper_rnn.device),\n",
    "                \"hidden_state\":hyper_hidden\n",
    "            },\n",
    "            has_aux=True\n",
    "        )\n",
    "        hyper_hidden = aux_output[\"hidden_state\"]\n",
    "        output, hidden = out\n",
    "        l = criterion(output, target_line_tensor[i])\n",
    "        loss += l\n",
    "\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(dynamic_hyper_rnn.parameters(), 10.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    grad_dict = {}\n",
    "    for n, W in dynamic_hyper_rnn.named_parameters():\n",
    "        if W.grad is not None:\n",
    "            grad_dict[\"{}_grad\".format(n)] = float(torch.sum(W.grad).item())\n",
    "\n",
    "    # for p in rnn.parameters():\n",
    "    #     p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, {\"loss\":loss.item() / input_line_tensor.size(0), **grad_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "def train(hypernet, lr, n_iters):\n",
    "    writer = get_tensorboard_logger(\"TorchHyperRNN\")\n",
    "    optimizer = torch.optim.Adam(hypernet.parameters(), lr=lr)\n",
    "    bar = tqdm(np.arange(n_iters))\n",
    "\n",
    "    for i in bar:\n",
    "        category_tensor, input_line_tensor, target_line_tensor = randomTrainingExample()\n",
    "\n",
    "        start_time = dt.datetime.today().timestamp()\n",
    "\n",
    "        _, metrics = train_dynamic_hyper_rnn_step(hypernet, optimizer, category_tensor, input_line_tensor, target_line_tensor)\n",
    "\n",
    "        time_diff = (dt.datetime.today().timestamp() - start_time) + 1e-5\n",
    "\n",
    "        metrics[\"diff\"] = time_diff\n",
    "        for key in metrics:\n",
    "            writer.add_scalar(key, metrics[key], i)\n",
    "\n",
    "\n",
    "        loss = metrics['loss']\n",
    "        bar.set_description('Loss: {} Iters p sec: {}'.format(loss, str(time_diff)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Follow tensorboard logs with: python -m tensorboard.main --logdir '/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/tensorboard_logs/TorchHyperRNN_2023-01-17 12:47:14.421052'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 3.6569724082946777 Iters p sec: 0.030779824981689453:  16%|█▌        | 7777/50000 [03:11<17:19, 40.63it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000015?line=0'>1</a>\u001b[0m learning_rate \u001b[39m=\u001b[39m \u001b[39m0.0001\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000015?line=2'>3</a>\u001b[0m train(hypernet\u001b[39m=\u001b[39;49mhypernetwork, lr\u001b[39m=\u001b[39;49mlearning_rate, n_iters\u001b[39m=\u001b[39;49m\u001b[39m50000\u001b[39;49m)\n",
      "\u001b[1;32m/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb Cell 15'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(hypernet, lr, n_iters)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000014?line=12'>13</a>\u001b[0m category_tensor, input_line_tensor, target_line_tensor \u001b[39m=\u001b[39m randomTrainingExample()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000014?line=14'>15</a>\u001b[0m start_time \u001b[39m=\u001b[39m dt\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mtoday()\u001b[39m.\u001b[39mtimestamp()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000014?line=16'>17</a>\u001b[0m _, metrics \u001b[39m=\u001b[39m train_dynamic_hyper_rnn_step(hypernet, optimizer, category_tensor, input_line_tensor, target_line_tensor)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000014?line=18'>19</a>\u001b[0m time_diff \u001b[39m=\u001b[39m (dt\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mtoday()\u001b[39m.\u001b[39mtimestamp() \u001b[39m-\u001b[39m start_time) \u001b[39m+\u001b[39m \u001b[39m1e-5\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000014?line=20'>21</a>\u001b[0m metrics[\u001b[39m\"\u001b[39m\u001b[39mdiff\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m time_diff\n",
      "\u001b[1;32m/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb Cell 14'\u001b[0m in \u001b[0;36mtrain_dynamic_hyper_rnn_step\u001b[0;34m(dynamic_hyper_rnn, optimizer, category_tensor, input_line_tensor, target_line_tensor)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000013?line=12'>13</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000013?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(input_line_tensor\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000013?line=15'>16</a>\u001b[0m     out, _, aux_output \u001b[39m=\u001b[39m dynamic_hyper_rnn(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000013?line=16'>17</a>\u001b[0m         category_tensor\u001b[39m.\u001b[39;49mto(dynamic_hyper_rnn\u001b[39m.\u001b[39;49mdevice),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000013?line=17'>18</a>\u001b[0m         input_line_tensor[i]\u001b[39m.\u001b[39;49mto(dynamic_hyper_rnn\u001b[39m.\u001b[39;49mdevice),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000013?line=18'>19</a>\u001b[0m         hidden,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000013?line=19'>20</a>\u001b[0m         generate_params_kwargs\u001b[39m=\u001b[39;49m{\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000013?line=20'>21</a>\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mcategory_tensor\u001b[39;49m\u001b[39m\"\u001b[39;49m:category_tensor\u001b[39m.\u001b[39;49mto(dynamic_hyper_rnn\u001b[39m.\u001b[39;49mdevice),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000013?line=21'>22</a>\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39minput_tensor\u001b[39;49m\u001b[39m\"\u001b[39;49m:input_line_tensor[i]\u001b[39m.\u001b[39;49mto(dynamic_hyper_rnn\u001b[39m.\u001b[39;49mdevice),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000013?line=22'>23</a>\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mhidden_state\u001b[39;49m\u001b[39m\"\u001b[39;49m:hyper_hidden\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000013?line=23'>24</a>\u001b[0m         },\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000013?line=24'>25</a>\u001b[0m         has_aux\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000013?line=25'>26</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000013?line=26'>27</a>\u001b[0m     hyper_hidden \u001b[39m=\u001b[39m aux_output[\u001b[39m\"\u001b[39m\u001b[39mhidden_state\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000013?line=27'>28</a>\u001b[0m     output, hidden \u001b[39m=\u001b[39m out\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1189'>1190</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1190'>1191</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1191'>1192</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1192'>1193</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1193'>1194</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1194'>1195</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1195'>1196</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py:86\u001b[0m, in \u001b[0;36mTorchHyperNetwork.forward\u001b[0;34m(self, generated_params, has_aux, assert_parameter_shapes, generate_params_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=79'>80</a>\u001b[0m     generated_params, aux_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_params(\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=80'>81</a>\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgenerate_params_kwargs\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=81'>82</a>\u001b[0m     )\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=83'>84</a>\u001b[0m \u001b[39mif\u001b[39;00m has_aux:\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=84'>85</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m---> <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=85'>86</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_forward(\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=86'>87</a>\u001b[0m             \u001b[39m*\u001b[39;49margs,\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=87'>88</a>\u001b[0m             generated_params\u001b[39m=\u001b[39;49mgenerated_params,\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=88'>89</a>\u001b[0m             assert_parameter_shapes\u001b[39m=\u001b[39;49massert_parameter_shapes,\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=89'>90</a>\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=90'>91</a>\u001b[0m         ),\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=91'>92</a>\u001b[0m         generated_params,\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=92'>93</a>\u001b[0m         aux_output,\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=93'>94</a>\u001b[0m     )\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=94'>95</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_forward(\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=95'>96</a>\u001b[0m     \u001b[39m*\u001b[39margs,\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=96'>97</a>\u001b[0m     generated_params\u001b[39m=\u001b[39mgenerated_params,\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=97'>98</a>\u001b[0m     assert_parameter_shapes\u001b[39m=\u001b[39massert_parameter_shapes,\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=98'>99</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=99'>100</a>\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py:55\u001b[0m, in \u001b[0;36mTorchHyperNetwork.target_forward\u001b[0;34m(self, generated_params, assert_parameter_shapes, *args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=51'>52</a>\u001b[0m \u001b[39mif\u001b[39;00m assert_parameter_shapes:\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=52'>53</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39massert_parameter_shapes(generated_params)\n\u001b[0;32m---> <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/hypernet.py?line=54'>55</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunctional_target_network(generated_params, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1189'>1190</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1190'>1191</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1191'>1192</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1192'>1193</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1193'>1194</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1194'>1195</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1195'>1196</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/utils.py:51\u001b[0m, in \u001b[0;36mFunctionalParamVectorWrapper.forward\u001b[0;34m(self, param_vector, *args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/utils.py?line=48'>49</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcustom_buffers \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/utils.py?line=49'>50</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunctional[\u001b[39m0\u001b[39m](params, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcustom_buffers, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/hyper_nn-0.2.1-py3.9.egg/hypernn/torch/utils.py?line=50'>51</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunctional[\u001b[39m0\u001b[39;49m](params, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1189'>1190</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1190'>1191</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1191'>1192</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1192'>1193</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1193'>1194</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1194'>1195</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1195'>1196</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/functorch/_src/make_functional.py:313\u001b[0m, in \u001b[0;36mFunctionalModule.forward\u001b[0;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/functorch/_src/make_functional.py?line=310'>311</a>\u001b[0m old_state \u001b[39m=\u001b[39m _swap_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstateless_model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames_map, params)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/functorch/_src/make_functional.py?line=311'>312</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/functorch/_src/make_functional.py?line=312'>313</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstateless_model(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/functorch/_src/make_functional.py?line=313'>314</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/functorch/_src/make_functional.py?line=314'>315</a>\u001b[0m     \u001b[39m# Remove the loaded state on self.stateless_model\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/functorch/_src/make_functional.py?line=315'>316</a>\u001b[0m     _swap_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstateless_model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames_map, old_state)\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1189'>1190</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1190'>1191</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1191'>1192</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1192'>1193</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1193'>1194</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1194'>1195</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1195'>1196</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb Cell 6'\u001b[0m in \u001b[0;36mTargetRNN.forward\u001b[0;34m(self, category, inp, hidden)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000005?line=16'>17</a>\u001b[0m concatenated \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((category, inp), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000005?line=17'>18</a>\u001b[0m hidden \u001b[39m=\u001b[39m  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrnn(concatenated, hidden)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000005?line=19'>20</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear(hidden)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000005?line=20'>21</a>\u001b[0m output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(output)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shyam/Code/hyper-nn/notebooks/dynamic_hypernetworks/TorchDynamicHyperRNN.ipynb#ch0000005?line=21'>22</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear2(output)\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1189'>1190</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1190'>1191</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1191'>1192</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1192'>1193</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1193'>1194</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1194'>1195</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1195'>1196</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/linear.py?line=112'>113</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/linear.py?line=113'>114</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0001\n",
    "\n",
    "train(hypernet=hypernetwork, lr=learning_rate, n_iters=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypernetwork = hypernetwork.to(torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ronr\n",
      "Uaaaab\n",
      "Sanat\n",
      "Gor\n",
      "Eosr\n",
      "Rosri\n",
      "Siru\n",
      "Pale\n",
      "Aiei\n",
      "Cha\n",
      "Hau\n",
      "Iit\n"
     ]
    }
   ],
   "source": [
    "max_length = 20\n",
    "\n",
    "# Sample from a category and starting letter\n",
    "def sample(category, start_letter='A'):\n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "        category_tensor = categoryTensor(category)\n",
    "        input = inputTensor(start_letter)\n",
    "        hidden = target_network.initHidden()\n",
    "        hyper_hidden = hypernetwork.embedding_module.init_hidden()\n",
    "\n",
    "        output_name = start_letter\n",
    "\n",
    "        hidden_states = []\n",
    "        for i in range(max_length):\n",
    "            out, _, aux_output = hypernetwork(\n",
    "                category_tensor,\n",
    "                input[0],\n",
    "                hidden,\n",
    "                generate_params_kwargs={\n",
    "                    \"category_tensor\":category_tensor,\n",
    "                    \"input_tensor\":input[0],\n",
    "                    \"hidden_state\":hyper_hidden\n",
    "                },\n",
    "                has_aux=True\n",
    "            )\n",
    "            hyper_hidden = aux_output[\"hidden_state\"]\n",
    "            output, hidden = out\n",
    "            topv, topi = output.topk(1)\n",
    "            topi = topi[0][0]\n",
    "            if topi == n_letters - 1:\n",
    "                break\n",
    "            else:\n",
    "                letter = all_letters[topi]\n",
    "                output_name += letter\n",
    "            input = inputTensor(letter)\n",
    "\n",
    "        return output_name\n",
    "\n",
    "# Get multiple samples from one category and multiple starting letters\n",
    "def samples(category, start_letters='ABC'):\n",
    "    for start_letter in start_letters:\n",
    "        print(sample(category, start_letter))\n",
    "\n",
    "samples('Russian', 'RUS')\n",
    "\n",
    "samples('German', 'GER')\n",
    "\n",
    "samples('Spanish', 'SPA')\n",
    "\n",
    "samples('Chinese', 'CHI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gor\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():  # no need to track history in sampling\n",
    "    category_tensor = categoryTensor(\"German\")\n",
    "    input = inputTensor(\"G\")\n",
    "    hidden = target_network.initHidden()\n",
    "    hyper_hidden = hypernetwork.embedding_module.init_hidden()\n",
    "\n",
    "    output_name = \"G\"\n",
    "\n",
    "    hidden_states = []\n",
    "    for i in range(max_length):\n",
    "        out, _, aux_output = hypernetwork(\n",
    "                category_tensor,\n",
    "                input[0],\n",
    "                hidden,\n",
    "                generate_params_kwargs={\n",
    "                    \"category_tensor\":category_tensor,\n",
    "                    \"input_tensor\":input[0],\n",
    "                    \"hidden_state\":hyper_hidden\n",
    "                },\n",
    "                has_aux=True\n",
    "            )\n",
    "        hyper_hidden = aux_output[\"hidden_state\"]\n",
    "        hidden_states.append(hyper_hidden)\n",
    "        output, hidden = out\n",
    "        topv, topi = output.topk(1)\n",
    "        topi = topi[0][0]\n",
    "        if topi == n_letters - 1:\n",
    "            break\n",
    "        else:\n",
    "            letter = all_letters[topi]\n",
    "            output_name += letter\n",
    "        input = inputTensor(letter)\n",
    "    print(output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_state_images = [((h - h.min()) / (h.max() - h.min())).detach().cpu().numpy() for h in hidden_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1ef257247c44c7b32caab5792a98a8",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4QAAAH0CAYAAABl8+PTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzZElEQVR4nO3dd5RV5b0//s/QmxQREcSMiNiw5YtRIyKIEUWwoSCCQfEXSywEleDVRFGxxK7RGBUNXgXsJCYkdmzRBHOvvYOCsQuIYB9h9u+PrDmXYeYg6s45E5/Xa61Zy9nPnnPec+Zsmfc8ez+7IsuyLAAAAEhOo3IHAAAAoDwUQgAAgEQphAAAAIlSCAEAABKlEAIAACRKIQQAAEiUQggAAJAohRAAACBRCiEAAECiFEIgCf3794/+/fv/2x5//fXXj0MOOaTw+YMPPhgVFRXx4IMP/tuek2+uoqIiTjvttHLHKDjkkEOiTZs2JXmuld+rxVx33XVRUVER8+fPL2z7dx9HpTJ//vyoqKiI6667rsHlOO2006KioqLkWRraMQGUjkIIiar5Za/mo0WLFtG1a9fYbbfd4te//nV89NFH5Y5IPZ555pkYM2ZMdO/ePVq0aBFt2rSJrbfeOiZMmBCvvfZauePlavr06XHJJZeU7flrflkv9vGrX/2qbNmo7aKLLoqKioq47777iu4zefLkqKioiD/+8Y8lTAbQ8DUpdwCgvM4444zo3r17fPnll/Huu+/Ggw8+GOPGjYuLLroo/vjHP8aWW25Z7oi5uOeee8od4VubPHly/PSnP4211lorRo0aFZtsskksW7Ysnnvuubj++uvjkksuic8++ywaN25c7qi5mD59ejz33HMxbty4suY48MADY4899qiz/fvf/34Z0pRXQz2ORowYET//+c9j+vTp8aMf/ajefaZPnx4dO3aMQYMGRZMmTeKzzz6Lpk2bljjpV/vlL38Z//Vf/1XuGEBCFEJI3KBBg2KbbbYpfH7SSSfFrFmzYsiQIbHXXnvFiy++GC1btixjwnw0a9as3BG+lcceeyx++tOfRp8+fWLmzJmxxhpr1Bq/8MIL46yzzipTutXz6aefRqtWrcod42v7f//v/8VBBx1U7hgNQkM9jrp27Ro777xzzJgxI377299G8+bNa42/9dZb8fDDD8fhhx9eKIEtWrQoR9Sv1KRJk2jSxK9nQOk4ZRSoY8CAAXHKKafE66+/HlOnTo2IiClTpkRFRUU8+eSTdfY/++yzo3HjxvHWW29FxL+uM9p8883jhRdeiJ133jlatWoV6667bpx33nm1vq6qqipOPfXU6N27d7Rr1y5at24dffv2jQceeKDWfjWn7l1wwQXxm9/8JjbYYINo1apVDBw4MN54443IsiwmTZoU3bp1i5YtW8bee+8dH3zwQa3HqO/ap88//zxOO+202GijjaJFixbRpUuXGDp0aLz66quFfS644ILYYYcdomPHjtGyZcvo3bt33HbbbV/7NZ04cWI0bdo0FixYUGfs8MMPj/bt28fnn39e9OtPP/30qKioiGnTptUpgxH/+uV20qRJdWYHZ8+eHbvvvnu0a9cuWrVqFf369YtHH3201j411yzNnTs3DjnkkGjfvn20a9cuxowZE59++mmd55o6dWr07t07WrZsGWuuuWaMGDEi3njjjVr71LwH/vd//zd22mmnaNWqVZx88skREXHHHXfE4MGDo2vXrtG8efPo0aNHTJo0KZYvX17r6//85z/H66+/XjhFc/311y+Mf/HFFzFx4sTYcMMNo3nz5rHeeuvFhAkT4osvvqiV44svvojjjjsuOnXqFGussUbstdde8eabbxZ9nb+p9ddfP4YMGRIPPvhgbLPNNtGyZcvYYostCteQzpgxI7bYYoto0aJF9O7du97jKCLitddei9122y1at24dXbt2jTPOOCOyLKu1T3V1dVxyySXRq1evaNGiRXTu3DmOOOKIWLx4ca39siyLM888M7p16xatWrWKnXfeOZ5//vl6n/f555+PAQMGRMuWLaNbt25x5plnRnV1dZ39Vj6Oaq6VveWWW+Kss86Kbt26RYsWLWKXXXaJuXPn1vn6muO3ZcuWse2228YjjzxS77F52WWXRa9evaJVq1bRoUOH2GabbWL69On1Zq9x0EEHxZIlS+LPf/5znbGbbropqqurY9SoURFR/7V77777bowZMya6desWzZs3jy5dusTee+9d6xrKYtfZrXxd5gcffBDjx4+PLbbYItq0aRNt27aNQYMGxdNPP73K7yGi7jWEhxxySNHTllfM0tCOCeA/hz9BAfX68Y9/HCeffHLcc889cdhhh8X+++8fRx99dEybNq3OqXLTpk2L/v37x7rrrlvYtnjx4th9991j6NChMXz48LjtttvixBNPjC222CIGDRoUERFLly6Na665Jg488MA47LDD4qOPPoprr702dtttt3j88cdj6623rvM8VVVVceyxx8YHH3wQ5513XgwfPjwGDBgQDz74YJx44okxd+7cuOyyy2L8+PHxu9/9ruj3t3z58hgyZEjcf//9MWLEiPjZz34WH330Udx7773x3HPPRY8ePSIi4tJLL4299torRo0aFVVVVXHTTTfFsGHDYubMmTF48OCv9XqeccYZcfPNN8cxxxxT2F5VVRW33XZb7LfffkVnLD799NOYNWtW9O/fP7p167bazzlr1qwYNGhQ9O7dOyZOnBiNGjWKKVOmxIABA+KRRx6Jbbfdttb+w4cPj+7du8c555wTTzzxRFxzzTWx9tprx7nnnlvY56yzzopTTjklhg8fHj/5yU9iwYIFcdlll8VOO+0UTz75ZLRv376w76JFi2LQoEExYsSIOOigg6Jz584R8a/rV9u0aRPHH398tGnTJmbNmhWnnnpqLF26NM4///yIiPjFL34RS5YsiTfffDMuvvjiiIjCoivV1dWx1157xV//+tc4/PDDY9NNN41nn302Lr744njllVfiD3/4QyHDT37yk5g6dWqMHDkydthhh5g1a9bX+rnVvP4LFy6ss719+/a1ZnLmzp0bI0eOjCOOOCIOOuiguOCCC2LPPfeMK6+8Mk4++eQ46qijIiLinHPOieHDh8fLL78cjRr9399lly9fHrvvvntsv/32cd5558Vdd90VEydOjGXLlsUZZ5xR2O+II46I6667LsaMGRNjx46NefPmxeWXXx5PPvlkPProo4UZsFNPPTXOPPPM2GOPPWKPPfaIJ554IgYOHBhVVVW1vo933303dt5551i2bFn813/9V7Ru3Tquvvrqr3VmwK9+9ato1KhRjB8/PpYsWRLnnXdejBo1KmbPnl3Y57e//W0cc8wx0bdv3zjuuONi/vz5sc8++0SHDh1qva8nT54cY8eOjf333z9+9rOfxeeffx7PPPNMzJ49O0aOHFk0w9ChQ+OnP/1pTJ8+PYYOHVprbPr06VFZWRl9+vQp+vX77bdfPP/883HsscfG+uuvH++//37ce++98c9//rPWHyNWx2uvvRZ/+MMfYtiwYdG9e/d477334qqrrop+/frFCy+8EF27dl3txzriiCPqnAZ71113xbRp02LttdeOiNIfE8B3TAYkacqUKVlEZP/4xz+K7tOuXbvs+9//fuHzAw88MOvatWu2fPnywrYnnngii4hsypQphW39+vXLIiK7/vrrC9u++OKLbJ111sn222+/wrZly5ZlX3zxRa3nXLx4cda5c+fs0EMPLWybN29eFhFZp06dsg8//LCw/aSTTsoiIttqq62yL7/8slbOZs2aZZ9//nmtTP369St8/rvf/S6LiOyiiy6q831XV1cX/vvTTz+tNVZVVZVtvvnm2YABA2ptr6yszA4++ODC5w888EAWEdkDDzxQ2PbDH/4w22677Wp93YwZM+rst7Knn346i4hs3LhxdcYWLVqULViwoPBR83pWV1dnPXv2zHbbbbc630/37t2zXXfdtbBt4sSJWUTUes2zLMv23XffrGPHjoXP58+fnzVu3Dg766yzau337LPPZk2aNKm1veY9cOWVV9bJvPJrmmVZdsQRR2StWrWq9TMbPHhwVllZWWffG264IWvUqFH2yCOP1Np+5ZVXZhGRPfroo1mWZdlTTz2VRUR21FFH1dpv5MiRWURkEydOrPPYK6p53xX7+Nvf/lbYt7KyMouI7LHHHitsu/vuu7OIyFq2bJm9/vrrhe1XXXVVnZ/5wQcfnEVEduyxxxa2VVdXZ4MHD86aNWuWLViwIMuyLHvkkUeyiMimTZtWK+tdd91Va/v777+fNWvWLBs8eHCtn//JJ5+cRUSt9+q4ceOyiMhmz55d2Pb+++9n7dq1yyIimzdvXmH7ysdRzft80003rXUsX3rppVlEZM8++2yWZf86/jt27Jj94Ac/qHWsXnfddVlE1HrMvffeO+vVq1f2TQwbNixr0aJFtmTJksK2l156KYuI7KSTTipsq/nZ1vx/a/HixVlEZOeff/4qH7/Y+2bl4//zzz+v9f/Jmuds3rx5dsYZZxTNkWX/dzwWM2fOnKxdu3bZrrvumi1btizLstIdE8B3k1NGgaLatGlTa7XR0aNHx9tvv13rlM5p06ZFy5YtY7/99qvztSted9WsWbPYdttta62E2bhx48I1SdXV1fHBBx/EsmXLYptttoknnniiTp5hw4ZFu3btCp9vt912EfGvU8VWnKnZbrvtoqqqqnAKa31uv/32WGutteLYY4+tM7bi6VorzpIsXrw4lixZEn379q0331cZPXp0zJ49u9YpqdOmTYv11lsv+vXrV/Trli5dGhFR720JNthgg+jUqVPho2YFxaeeeirmzJkTI0eOjEWLFsXChQtj4cKF8cknn8Quu+wSDz/8cJ1TAo888shan/ft2zcWLVpUeP4ZM2ZEdXV1DB8+vPB4CxcujHXWWSd69uxZ51Tf5s2bx5gxY+pkXvE1/eijj2LhwoXRt2/f+PTTT+Oll14q+jrUuPXWW2PTTTeNTTbZpFaOAQMGREQUcvzlL3+JiIixY8fW+vqvu0jN4YcfHvfee2+dj80226zWfptttln88Ic/LHxe8/4cMGBAfO9736uzvb5VYVecPa6oqIhjjjkmqqqqCqtn3nrrrdGuXbvYdddda33vvXv3jjZt2hS+9/vuu68wm77i+7m+7/0vf/lLbL/99rVmjDt16lQ4vXJ1jBkzptb1hX379q31Pf7P//xPLFq0KA477LBax+qoUaOiQ4cOtR6rffv28eabb8Y//vGP1X7+GgcddFB8/vnnMWPGjMK2mlNNV/X9tGzZMpo1axYPPvhgnVNvv4nmzZsXZn+XL18eixYtijZt2sTGG2/8jf7fUeOTTz6JfffdNzp06BA33nhj4RTxUh8TwHeLU0aBoj7++OPCKUkREbvuumt06dIlpk2bFrvssktUV1fHjTfeGHvvvXed69q6detW515aHTp0iGeeeabWtv/+7/+OCy+8MF566aX48ssvC9u7d+9eJ8+Kv1RHRKEcrrfeevVuX9Uvdq+++mpsvPHGX7l4w8yZM+PMM8+Mp556qta1ON/kPmEHHHBAjBs3LqZNmxannnpqLFmyJGbOnBnHHXfcKh+v5rX9+OOP64zdcccd8eWXX8bTTz8d48ePL2yfM2dOREQcfPDBRR93yZIltX4ZX/n1rRlbvHhxtG3bNubMmRNZlkXPnj3rfbyVV2xcd911612E5Pnnn49f/vKXMWvWrELZXDHTV5kzZ068+OKL0alTp3rH33///YiIeP3116NRo0aF039rbLzxxl/5HCvq2bNn0ZUrV/Rt35+NGjWKDTbYoNa2jTbaKCKicB3bnDlzYsmSJbWOyxWt+L3XZF9Rp06d6hSw119/vVBSV/R1XqdVvXdWzLPhhhvW2q9JkyZ1Tsc88cQT47777ottt902Ntxwwxg4cGCMHDlylad71hg0aFCsueaaMX369MI1fTfeeGNstdVW0atXr6Jf17x58zj33HPjhBNOiM6dO8f2228fQ4YMidGjR8c666zzlc+7surq6rj00kvjiiuuiHnz5tW6PrZjx45f+/FqHHbYYfHqq6/GY489VutxSn1MAN8tCiFQrzfffDOWLFlS6xe4xo0bx8iRI2Py5MlxxRVXxKOPPhpvv/12vSswFrv1QbbCAhlTp06NQw45JPbZZ5/4+c9/HmuvvXY0btw4zjnnnFqzaF/1mKvzXN/EI488EnvttVfstNNOccUVV0SXLl2iadOmMWXKlK9c4KI+HTp0iCFDhhQK4W233RZffPHFV65gueGGG0aTJk3iueeeqzNWM7O4crGtmf07//zz61yLWWPlGceveh2rq6ujoqIi7rzzznr3Xfnx6rsG7cMPP4x+/fpF27Zt44wzzogePXpEixYt4oknnogTTzyx3oVMVlZdXR1bbLFFXHTRRfWOr1zASqUU78/q6upYe+21Y9q0afWOFysE/255fo+bbrppvPzyyzFz5sy466674vbbb48rrrgiTj311Dj99NNX+bVNmzaN4cOHx+TJk+O9996Lf/7znzFnzpw6C1rVZ9y4cbHnnnvGH/7wh7j77rvjlFNOiXPOOSdmzZr1lbcYWbHwRfxroa1TTjklDj300Jg0aVKsueaa0ahRoxg3btxqvcfrc+mll8aNN94YU6dOrXNMN9RjAvjPoBAC9brhhhsiImK33XartX306NFx4YUXxp/+9Ke48847o1OnTnX2WV233XZbbLDBBjFjxoxaM2QTJ0785sFXU48ePWL27Nnx5ZdfFr0X2e233x4tWrSIu+++u9Yy9lOmTPnGzzt69OjYe++94x//+EdhgZ5VzVxERLRu3Tr69+8fDz30ULz11lu1Fu8ppmYGoG3btqs1u7U6evToEVmWRffu3QszV1/Xgw8+GIsWLYoZM2bETjvtVNg+b968OvsWmzXt0aNHPP3007HLLruscma1srIyqqurC7PBNV5++eVvlP3frbq6Ol577bVar+0rr7wSEVGYRevRo0fcd9990adPn1Uu+lJZWRkR/5o5WnHWccGCBXVmJisrKwszyivK83WqyTN37tzYeeedC9uXLVsW8+fPr3O/09atW8cBBxwQBxxwQFRVVcXQoUPjrLPOipNOOukrbxcxatSouPLKK+Pmm2+OefPmRUVFRRx44IGrlbNHjx5xwgknxAknnBBz5syJrbfeOi688MLCassdOnSIDz/8sNbXVFVVxTvvvFNr22233RY777xzXHvttbW2f/jhh7HWWmutVpYVPfLIIzF+/PgYN25cvae+flePCaA0XEMI1DFr1qyYNGlSdO/evc4vH1tuuWVsueWWcc0118Ttt98eI0aM+Mb3zKqZVVhxFmH27Nnxt7/97ZuHX0377bdfLFy4MC6//PI6YzV5GjduHBUVFbX++j9//vxaK/Z9XYMGDYq11lorzj333HjooYdW+/52p556aixfvjwOOuigek8dXXkmpnfv3tGjR4+44IIL6t2/vttffJWhQ4dG48aN4/TTT6/zfFmWxaJFi77yMer7mVdVVcUVV1xRZ9/WrVvXewrp8OHD46233orJkyfXGfvss8/ik08+iYgorGb761//utY+l1xyyVfmLJcV349ZlsXll18eTZs2jV122SUi/vW9L1++PCZNmlTna5ctW1YoKz/60Y+iadOmcdlll9V6rev73vfYY4/4+9//Ho8//nhh24IFC4rOQn4T22yzTXTs2DEmT54cy5YtK2yfNm1anYK68vuoWbNmsdlmm0WWZbVOKy+mT58+sf7668fUqVPj5ptvjn79+n3l6ryffvppndu+9OjRI9ZYY41ap4r36NEjHn744Vr7XX311XVmCBs3blznGLn11ltXeV1zMe+8804MHz48dtxxx8IqvCv7Lh8TwL+fGUJI3J133hkvvfRSLFu2LN57772YNWtW3HvvvVFZWRl//OMf6/1r/OjRowvXq32bG3YPGTIkZsyYEfvuu28MHjw45s2bF1deeWVsttlm9ZaYPI0ePTquv/76OP744+Pxxx+Pvn37xieffBL33XdfHHXUUbH33nvH4MGD46KLLordd989Ro4cGe+//3785je/iQ033LDOtZCrq2nTpjFixIi4/PLLo3Hjxqs9c9G3b9+4/PLL49hjj42ePXvGqFGjYpNNNomqqqp45ZVXYtq0adGsWbPC9U6NGjWKa665JgYNGhS9evWKMWPGxLrrrhtvvfVWPPDAA9G2bdv405/+9LWy9+jRI84888w46aSTCrcMWGONNWLevHnx+9//Pg4//PBa1zHWZ4cddogOHTrEwQcfHGPHjo2Kioq44YYb6j21sHfv3nHzzTfH8ccfHz/4wQ+iTZs2seeee8aPf/zjuOWWW+LII4+MBx54IPr06RPLly+Pl156KW655Za4++67Y5tttomtt946DjzwwLjiiitiyZIlscMOO8T9999f7/3xVuWJJ54ozBCt/HqsuIjMt9WiRYu466674uCDD47tttsu7rzzzvjzn/8cJ598cuFU0H79+sURRxwR55xzTjz11FMxcODAaNq0acyZMyduvfXWuPTSS2P//fePTp06xfjx4+Occ86JIUOGxB577BFPPvlk3HnnnXVmqCZMmBA33HBD7L777vGzn/2scNuJysrKb/w+X1mzZs3itNNOi2OPPTYGDBgQw4cPj/nz58d1110XPXr0qDWrNXDgwFhnnXWiT58+0blz53jxxRfj8ssvj8GDB9d7D86VVVRUxMiRI+Pss8+OiKh1y45iXnnlldhll11i+PDhsdlmm0WTJk3i97//fbz33nsxYsSIwn4/+clP4sgjj4z99tsvdt1113j66afj7rvvrvOaDhkyJM4444wYM2ZM7LDDDvHss8/GtGnT6lwjujrGjh0bCxYsiAkTJsRNN91Ua6zmD3SlPiaA75hSL2sKNAw1t52o+WjWrFm2zjrrZLvuumt26aWXZkuXLi36te+8807WuHHjbKONNqp3vF+/fvUuG3/wwQfXuo1AdXV1dvbZZ2eVlZVZ8+bNs+9///vZzJkz6+xXszT7ykvC1yx5f+utt9b7va14S42Vl8vPsn/d/uAXv/hF1r1796xp06bZOuusk+2///7Zq6++Wtjn2muvzXr27Jk1b94822STTbIpU6bUuyz86tx2osbjjz+eRUQ2cODAOmNf5cknn8xGjx6dfe9738uaNWuWtW7dOttyyy2zE044IZs7d269+w8dOjTr2LFj1rx586yysjIbPnx4dv/99xf2qfl+am5tUKPmdVzxtgNZlmW33357tuOOO2atW7fOWrdunW2yySbZ0Ucfnb388suFfYq9B7Isyx599NFs++23z1q2bJl17do1mzBhQuEWDSu+Xh9//HE2cuTIrH379llE1HpPVFVVZeeee27Wq1evrHnz5lmHDh2y3r17Z6effnqtWw589tln2dixY7OOHTtmrVu3zvbcc8/sjTfeyOW2Eyv+vCsrK7PBgwfXeYyIyI4++uh6H3fF9/PBBx+ctW7dOnv11VezgQMHZq1atco6d+6cTZw4sc7tC7Isy66++uqsd+/eWcuWLbM11lgj22KLLbIJEyZkb7/9dmGf5cuXZ6effnrWpUuXrGXLlln//v2z5557rs57Ncuy7Jlnnsn69euXtWjRIlt33XWzSZMmZddee+1q33Zi5WOwvtspZFmW/frXvy4c79tuu2326KOPZr1798523333wj5XXXVVttNOOxXesz169Mh+/vOf1/q5fpXnn38+i4isefPm2eLFi+uMr5xv4cKF2dFHH51tsskmWevWrbN27dpl2223XXbLLbfU+rrly5dnJ554YrbWWmtlrVq1ynbbbbds7ty59d524oQTTii89n369Mn+9re/1Xn9Vue2EzW3cKnvY8X3cCmOCeC7qSLLvuWqC0ByFi5cGF26dIlTTz01TjnllHLH+Y/z9NNPx9Zbbx3XX399/PjHPy53HCib6urq6NSpUwwdOrTe0x0B+PdzDSHwtV133XWxfPlyZeYbmjx5crRp0yaGDh1a7ihQMp9//nmdU4Ovv/76+OCDD6J///7lCQWAawiB1Tdr1qx44YUX4qyzzop99tmnzv3DWLU//elP8cILL8TVV18dxxxzTLRu3brckaBk/v73v8dxxx0Xw4YNi44dO8YTTzwR1157bWy++eYxbNiwcscDSJZTRoHV1r9//3jssceiT58+MXXq1NW6/QH/Z/3114/33nsvdtttt7jhhhtWa4EM+K6YP39+jB07Nh5//PH44IMPYs0114w99tgjfvWrX8Xaa69d7ngAyVIIAQAAEuUaQgAAgEQphAAAAIlSCAEAABKlEAIAACRKIQQAAEiUQggAAJAohRAAACBRCiEAAECiFEIAAIBEKYQAAACJUgghZ/PmzYtjjjkmNtpoo2jVqlW0atUqNttsszj66KPjmWeeKXc8AAAoqMiyLCt3CPiumDlzZhxwwAHRpEmTGDVqVGy11VbRqFGjeOmll2LGjBnx+uuvx7x586KysrLcUQEAQCGEvLz66qux1VZbxfe+9724//77o0uXLrXGly1bFldccUXsu+++sd5665UpJQBQzCeffBKtW7cudwwoKaeMQk7OO++8+OSTT2LKlCl1ymBERJMmTWLs2LHKIPwHevLJJ2PQoEHRtm3baNOmTeyyyy7x97//vdyxgG/htNNOi4qKinjhhRdi5MiR0aFDh9hxxx3LHQtKrkm5A8B3xcyZM2PDDTeM7bbbrtxRgBw9//zz0bdv32jbtm1MmDAhmjZtGldddVX0798/HnroIcc8/IcbNmxY9OzZM84+++xw4hwpUgghB0uXLo2333479tlnnzpjH374YSxbtqzweevWraNly5YlTAd8G7/85S/jyy+/jL/+9a+xwQYbRETE6NGjY+ONN44JEybEQw89VOaEwLex1VZbxfTp08sdA8rGKaOQg6VLl0ZERJs2beqM9e/fPzp16lT4+M1vflPqeMA3tHz58rjnnntin332KZTBiIguXbrEyJEj469//Wvh+Af+Mx155JHljgBlpRBCDtZYY42IiPj444/rjF111VVx7733xtSpU0sdC/iWFixYEJ9++mlsvPHGdcY23XTTqK6ujjfeeKMMyYC8dO/evdwRoKycMgo5aNeuXXTp0iWee+65OmM11xfNnz+/xKkAgK/iMg5SZ4YQcjJ48OCYO3duPP744+WOAuSkU6dO0apVq3j55ZfrjL300kvRqFEjKwcD8B9NIYScTJgwIVq1ahWHHnpovPfee3XGrVwG/3kaN24cAwcOjDvuuKPWLP97770X06dPjx133DHatm1bvoAA8C05ZRRy0rNnz5g+fXoceOCBsfHGG8eoUaNiq622iizLYt68eTF9+vRo1KhRdOvWrdxRga/hzDPPjHvvvTd23HHHOOqoo6JJkyZx1VVXxRdffBHnnXdeueMBwLeiEEKO9t5773j22WfjwgsvjHvuuSd+97vfRUVFRVRWVsbgwYPjyCOPjK222qrcMYGvoVevXvHII4/ESSedFOecc05UV1fHdtttF1OnTnUPQgD+41VkzmMDAABIkmsIAQAAEqUQAgAAJEohBAAASJRCCAAAkCiFEAAAIFEKIQAAQKIUQgAAgES5MT3kaKf7fl507OEfnV/CJEBeuk8/u+jYvJEnlzAJkJcNb5lUdGzu8FNKmATKzwwhAABAohRCAACARCmEAAAAiVIIAQAAEqUQAgAAJMoqo5CjN55fp/jgj0qXA8hP9cdNyx0ByFl1tTkRqOFoAAAASJRCCAAAkCiFEAAAIFEKIQAAQKIUQgAAgERZZRRy1Hl2uRMAeWu6uHG5IwA5W3d6s+KDI0qXAxoCM4QAAACJUggBAAASpRACAAAkSiEEAABIlEIIAACQKKuMQo5+ceZ1qxg9oVQxgBy16fVBuSMAOdvjnAdWMfrzkuWAhsAMIQAAQKIUQgAAgEQphAAAAIlSCAEAABKlEAIAACTKKqOQo+NuG1N0bM8JJQwC5Gbpxy3LHQHI2dX37lJ07KReJQwCDYAZQgAAgEQphAAAAIlSCAEAABKlEAIAACRKIQQAAEiUVUYhR+P3vmMVo8eXLAeQn6y6otwRgJxVVJc7ATQcZggBAAASpRACAAAkSiEEAABIlEIIAACQKIUQAAAgUVYZhRxdev0+RceOPKt0OYD8VH/ctNwRgJx1m7W8+KBFwUmMGUIAAIBEKYQAAACJUggBAAASpRACAAAkSiEEAABIlFVGIUeNVrFoGfCfqcPTjcsdAcjZOz/0KzDUMEMIAACQKIUQAAAgUQohAABAohRCAACARCmEAAAAibLEEuRo26HPlDsCkLMdDn2i3BGAnHX74VvljgANhhlCAACARCmEAAAAiVIIAQAAEqUQAgAAJEohBAAASJRVRiFHf319g+KD25YuB5Cfvzy+dfHB3iWLAeTotTc6lTsCNBhmCAEAABKlEAIAACRKIQQAAEiUQggAAJAohRAAACBRVhmFHC2ralzuCEDO2q/3YbkjADlr0aaq3BGgwTBDCAAAkCiFEAAAIFEKIQAAQKIUQgAAgEQphAAAAImyyijkqON9LYoPjipdDiA/1fd1LD44pHQ5gPx0mtay+OB+pcsBDYEZQgAAgEQphAAAAIlSCAEAABKlEAIAACRKIQQAAEiUVUYhRx8N+bjcEYCcbbD/nHJHAHL27gFflDsCNBhmCAEAABKlEAIAACRKIQQAAEiUQggAAJAohRAAACBRVhmFHL3Y54ZVjJ5ashxAfr7XenG5IwA5q3i1VbkjQINhhhAAACBRCiEAAECiFEIAAIBEKYQAAACJUggBAAASZZVRyNGWjx9YdOy5vUoYBMjNrDd6Fh/8fulyAPlZ4/VyJ4CGwwwhAABAohRCAACARCmEAAAAiVIIAQAAEqUQAgAAJMoqo5Cjzz5tXu4IQM7at/y83BGAnH1UWe4E0HCYIQQAAEiUQggAAJAohRAAACBRCiEAAECiFEIAAIBEWWUUcjRm87+VOwKQs57tFpQ7ApCzU4fdsorR40uWAxoCM4QAAACJUggBAAASpRACAAAkSiEEAABIlEIIAACQKKuMQo5e+qRzuSMAOdttzWfLHQHI2ag1FpU7AjQYZggBAAASpRACAAAkSiEEAABIlEIIAACQKIUQAAAgUVYZhRxN7PqXckcActY4snJHAHJ2/dK1io4dsk4Jg0ADYIYQAAAgUQohAABAohRCAACARCmEAAAAiVIIAQAAEmWVUcjRvr+eUHTsufNLGATIzRm/Oajo2LCLSxgEyM1N++1SdOyQZ0sYBBoAM4QAAACJUggBAAASpRACAAAkSiEEAABIlEIIAACQKKuMQo7WvW9xuSMAOWu5sLrcEYCcLenVodwRoMEwQwgAAJAohRAAACBRCiEAAECiFEIAAIBEKYQAAACJssoo5OiVQ9qVOwKQs65HvFruCEDOlh64tNwRoMEwQwgAAJAohRAAACBRCiEAAECiFEIAAIBEKYQAAACJssoo5KjntI+LD/6sdDmA/Cz8rE25IwA5q368ffHBvUsWAxoEM4QAAACJUggBAAASpRACAAAkSiEEAABIlEIIAACQKKuMQo5eObZZuSMAOftLrxtXMXpeyXIA+Tl+9IxVjB5XshzQEJghBAAASJRCCAAAkCiFEAAAIFEKIQAAQKIUQgAAgERZZRRytNF675U7ApCzLW8fV3Rs/rGlywHk594PNis6dlgJc0BDYIYQAAAgUQohAABAohRCAACARCmEAAAAiVIIAQAAEmWVUcjRyK6zyx0ByNnfh164itETSpYDyM8hnR8tdwRoMMwQAgAAJEohBAAASJRCCAAAkCiFEAAAIFEKIQAAQKKsMgo5mrZJt6Jjh1SXMAiQmx+v16fo2L2Oa/iPdPGGmxYd28NxTWLMEAIAACRKIQQAAEiUQggAAJAohRAAACBRCiEAAECirDIKOfr/XplX7ghAzqrurSx3BCBnr/x223JHgAbDDCEAAECiFEIAAIBEKYQAAACJUggBAAASpRACAAAkyiqjkKNJk0cVHRtxbgmDALlZXu1vp/Bd0/55vwJDDf/KAQAAJEohBAAASJRCCAAAkCiFEAAAIFEKIQAAQKIssQQ5+qJjVu4IQM7en71O8cFdS5cDyM9Hlf69hhpmCAEAABKlEAIAACRKIQQAAEiUQggAAJAohRAAACBRVhkFgFVo/FlFuSMAOWu2xHENNcwQAgAAJEohBAAASJRCCAAAkCiFEAAAIFEKIQAAQKKsMgo5OmfotFWMHl+yHEB+Tjz4llWMHleyHEB+lm/xcbkjQINhhhAAACBRCiEAAECiFEIAAIBEKYQAAACJUggBAAASZZVRyNH4R4cVHRu2YQmDALmZ+Ng+RccO2ah0OYD8VH3crNwRoMEwQwgAAJAohRAAACBRCiEAAECiFEIAAIBEKYQAAACJUggBAAAS5bYTkKPGi5qWOwKQs7ZrflLuCEDONu7+TrkjQINhhhAAACBRCiEAAECiFEIAAIBEKYQAAACJUggBAAASZZVRyNHy9svKHQHI2WefNSt3BCBnn37puIYaZggBAAASpRACAAAkSiEEAABIlEIIAACQKIUQAAAgUVYZhRx9745V/I3l0NLlAPKzQeeF5Y4A5OyjP3UpPrhr6XJAQ2CGEAAAIFEKIQAAQKIUQgAAgEQphAAAAIlSCAEAABJllVHI0T/3qS53BCBnr77bqdwRgJwt3cC/11DDDCEAAECiFEIAAIBEKYQAAACJUggBAAASpRACAAAkyiqjkKMmLZeVOwKQs702fqbcEYC8mRKBAocDAABAohRCAACARCmEAAAAiVIIAQAAEqUQAgAAJMoqo5Cjtg+1LD44onQ5gPzc8fKWRccu/n4JgwC5ydp/We4I0GCYIQQAAEiUQggAAJAohRAAACBRCiEAAECiFEIAAIBEVWRZlpU7BHxXTJ+zbdGxkT0fL2ESIC/V7/YsOtZonTklTALk5Z9vdik69r1u75QwCZSfGUIAAIBEKYQAAACJUggBAAASpRACAAAkSiEEAABIVJNyB4DvktNuOrDo2MhTShgEyE2vy48qOvbimSUMAuTmgPHji4797aYSBoEGwAwhAABAohRCAACARCmEAAAAiVIIAQAAEqUQAgAAJMoqo5CnTT8qdwIgZxcfOnkVo8eVLAeQn5Gn/XkVoyeULAc0BGYIAQAAEqUQAgAAJEohBAAASJRCCAAAkCiFEAAAIFFWGYUctb6vTfHB/UuXA8jPiRcfVnRs98tKGATIzdVX71l07NiLShgEGgAzhAAAAIlSCAEAABKlEAIAACRKIQQAAEiUQggAAJAoq4xCjq4/eVVLkx1fshxAftYb/lq5IwA5q+rzUbkjQINhhhAAACBRCiEAAECiFEIAAIBEKYQAAACJUggBAAASZZVRyNHRR48tOvbwn0oYBMjNc89UFh/sW7ocQH6Wv9qm3BGgwTBDCAAAkCiFEAAAIFEKIQAAQKIUQgAAgEQphAAAAImyyijk6PW9yp0AyNuwHWeXOwKQs+P3+uOqRkuWAxoCM4QAAACJUggBAAASpRACAAAkSiEEAABIlEIIAACQKKuMQo7W6PxxuSMAOfvL/M2Kjp2/VQmDALm54MmBRceO2qSEQaABMEMIAACQKIUQAAAgUQohAABAohRCAACARCmEAAAAibLKKORos07vlTsCkLOqKv9UwnfNjzefXe4I0GCYIQQAAEiUQggAAJAohRAAACBRCiEAAECiFEIAAIBEWToNcvTq4rXKHQHI2fRtr1nF6CklywHkZ62mH5U7AjQYZggBAAASpRACAAAkSiEEAABIlEIIAACQKIUQAAAgUVYZhRwtfLtduSMAOTv00nFFx569qHQ5gPxcfdWeRceOvbiEQaABMEMIAACQKIUQAAAgUQohAABAohRCAACARCmEAAAAibLKKORo/I53rWJ0QslyAPmpblbuBEDePq6sLncEaDDMEAIAACRKIQQAAEiUQggAAJAohRAAACBRCiEAAECiKrIsy8odAr4rthx3cdGxZy45roRJgLw8Nn+DomM7rP9aCZMAeZk+Z9uiYyN7Pl7CJFB+ZggBAAASpRACAAAkSiEEAABIlEIIAACQKIUQAAAgUU3KHQC+S9q8vbzcEYCcHXzjMUXH5pxUwiBAbiZdd2DRsZFnlTAINABmCAEAABKlEAIAACRKIQQAAEiUQggAAJAohRAAACBRVhmFHL2zT1W5IwA5O33/m1YxenzJcgD5+dnoP6xi9LhSxYAGwQwhAABAohRCAACARCmEAAAAiVIIAQAAEqUQAgAAJMoqo5CjC7e7dRWjJ5csB5Cfvy7dqOjYyBLmAPLzVlWHckeABsMMIQAAQKIUQgAAgEQphAAAAIlSCAEAABKlEAIAACTKKqOQo0c/6ll0bGgJcwD5eeaDruWOAOTs7rc2LTo2aYsSBoEGwAwhAABAohRCAACARCmEAAAAiVIIAQAAEqUQAgAAJMoqo5Cj3z+wXdGxC7cuXQ4gP19e17n44K6lywHkp+2ZrYsP7l66HNAQmCEEAABIlEIIAACQKIUQAAAgUQohAABAohRCAACARFllFHKUVZQ7AZC3Yb+4ZxWjJ5QsB5CfY/771lWM/rJkOaAhMEMIAACQKIUQAAAgUQohAABAohRCAACARCmEAAAAibLKKOSo1dv+xgLfNZc9/KOiY+M3K2EQIDfH/Xl00bF9xpYwCDQAfnsFAABIlEIIAACQKIUQAAAgUQohAABAohRCAACARFllFHL0yZaflzsCkLPma31W7ghAzqrXWFbuCNBgmCEEAABIlEIIAACQKIUQAAAgUQohAABAohRCAACARFllFHK0ZeVb5Y4A5OzkLe9cxeipJcsB5OdHm79Y7gjQYJghBAAASJRCCAAAkCiFEAAAIFEKIQAAQKIUQgAAgERZZRRytMfaz5Y7ApCzC17atejYIRuVMAiQm/tf3rj44A9KlwMaAjOEAAAAiVIIAQAAEqUQAgAAJEohBAAASJRCCAAAkCirjEKObjlq96JjR95fwiBAbtrc2K744F6lywHkZ5PjXy8+eFDpckBDYIYQAAAgUQohAABAohRCAACARCmEAAAAiVIIAQAAEmWVUcjR6N/+cRWjJ5UsB5CfjY97vtwRgJzd8fQ95Y4ADYYZQgAAgEQphAAAAIlSCAEAABKlEAIAACRKIQQAAEhURZZlWblDAAAAUHpmCAEAABKlEAIAACRKIQQAAEiUQggAAJAohRAAACBRCiEAAECiFEIAAIBEKYQAAACJUggBAAASpRACAAAkSiEEAABIlEIIAACQKIUQAAAgUQohAABAohRCAACARCmEAAAAiVIIAQAAEqUQAgAAJEohBAAASJRCCAAAkCiFEAAAIFEKIQAAQKIUQgAAgEQphAAAAIlSCAEAABKlEAIAACRKIQQAAEiUQggAAJAohRAAACBRCiEAAECiFEIAAIBEKYQAAACJUggBAAASpRACAAAkSiEEAABIlEIIAACQKIUQAAAgUQohAABAohRCAACARCmEAAAAiVIIAQAAEqUQAgAAJEohBAAASJRCCAAAkCiFEAAAIFEKIQAAQKIUQgAAgEQphAAAAIlSCAEAABKlEAIAACRKIQQAAEiUQggAAJAohRAAACBRCiEAAECi/n9T7rTL4Vrj+gAAAABJRU5ErkJggg==",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=900.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib ipympl\n",
    "f,axs=plt.subplots(1,len(hidden_state_images),figsize=(9,5)) #ROW,COLUMN\n",
    "f.suptitle(\"Dynamically Generated Embeddings Visualized\")\n",
    "# f.tight_layout() # Or equivalently,  \"plt.tight_layout()\"\n",
    "\n",
    "for i in range(len(hidden_state_images)):\n",
    "    img = hidden_state_images[i].reshape(64,1,1)\n",
    "    letter = output_name[i]\n",
    "    ax = axs[i]\n",
    "    ax.grid(False)\n",
    "    ax.axis('off')\n",
    "    ax.title.set_text(letter)\n",
    "    ax.imshow(img)\n",
    "    f.subplots_adjust(wspace=None, hspace=None)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e5f2d8038e6c8941d283a9a145e7dfd2f60905a23729a9c846dae091a9571f4"
  },
  "kernelspec": {
   "display_name": "Python [conda env:test_hyper_nn] *",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
