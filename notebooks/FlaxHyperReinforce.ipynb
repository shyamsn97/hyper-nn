{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this to install dependencies for this notebook\n",
    "# !pip install gym\n",
    "# !pip install tqdm\n",
    "# !pip install tensorboard\n",
    "# !pip install matplotlib\n",
    "# !pip install JSAnimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this to enable jax gpu preallocation, might lead to memory issues\n",
    "\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypernn.jax.embedding_module import FlaxEmbeddingModule\n",
    "from hypernn.jax.weight_generator import FlaxWeightGenerator\n",
    "from hypernn.jax.hypernet import FlaxHyperNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Any\n",
    "\n",
    "class CustomFlaxEmbeddingModule(FlaxEmbeddingModule):\n",
    "    def setup(self):\n",
    "        self.embedding = nn.Embed(self.num_embeddings, self.embedding_dim)\n",
    "\n",
    "    def __call__(self, inp: Optional[Any] = None):\n",
    "        indices = jnp.arange(0, self.num_embeddings)\n",
    "        return self.embedding(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFlaxWeightGenerator(FlaxWeightGenerator):\n",
    "    def setup(self):\n",
    "        self.dense1 = nn.Dense(32)\n",
    "        self.dense2 = nn.Dense(self.hidden_dim)\n",
    "\n",
    "    def __call__(self, embedding: jnp.array, inp: Optional[Any] = None):\n",
    "        x = self.dense1(embedding)\n",
    "        x = nn.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(256)(x)\n",
    "        x = nn.tanh(x)\n",
    "        x = nn.Dense(256)(x)\n",
    "        x = nn.tanh(x)\n",
    "        x = nn.Dense(4, use_bias=False)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "jnp.zeros(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_probability.substrates import jax as tfp\n",
    "\n",
    "import jax\n",
    "import functools\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=('apply_fn', 'method'))\n",
    "def generate_params(apply_fn, hypernetwork_params, method):\n",
    "    generated_params, _ = apply_fn({'params':hypernetwork_params}, jnp.zeros(0), method=method)\n",
    "    return generated_params\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=('apply_fn'))\n",
    "def sample_actions(apply_fn, hypernetwork_params, obs, generated_params):\n",
    "    out, _, _ =  apply_fn({'params':hypernetwork_params}, jnp.expand_dims(jnp.array(obs), 0), generated_params)\n",
    "    return out\n",
    "\n",
    "def rollout(env, hypernetwork, hypernetwork_params, render=False, seed: int = 0) -> float:\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    observations, actions, rewards, rendereds = [], [], [], []\n",
    "    generated_params = generate_params(hypernetwork.apply, hypernetwork_params, hypernetwork.generate_params)\n",
    "    while not done:\n",
    "        rendered = None\n",
    "        if render:\n",
    "            rendered = env.render(mode=\"rgb_array\")\n",
    "            rendereds.append(rendered)\n",
    "\n",
    "        out = sample_actions(hypernetwork.apply, hypernetwork_params, obs, generated_params)\n",
    "        out = jnp.squeeze(out)\n",
    "        dist = tfp.distributions.Categorical(logits=out)\n",
    "        rng = jax.random.PRNGKey(np.random.randint(0, 10**10))\n",
    "        action = dist.sample(seed=rng).item()\n",
    "        next_obs, r, done, _ = env.step(action)\n",
    "\n",
    "        observations.append(obs)\n",
    "        actions.append(action)\n",
    "        rewards.append(r)\n",
    "\n",
    "        obs = next_obs\n",
    "\n",
    "    num_steps = len(observations)\n",
    "    env.close()\n",
    "    return observations, actions, rewards, rendereds, num_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "def get_tensorboard_logger(\n",
    "    experiment_name: str, base_log_path: str = \"tensorboard_logs\"\n",
    "):\n",
    "    log_path = \"{}/{}_{}\".format(base_log_path, experiment_name, datetime.now())\n",
    "    train_writer = SummaryWriter(log_path, flush_secs=10)\n",
    "    full_log_path = os.path.join(os.getcwd(), log_path)\n",
    "    print(\n",
    "        \"Follow tensorboard logs with: tensorboard --logdir '{}'\".format(full_log_path)\n",
    "    )\n",
    "    return train_writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "from flax.training import train_state  # Useful dataclass to keep train state\n",
    "\n",
    "def create_train_state(rng, hypernetwork, learning_rate, input_shape):\n",
    "    \"\"\"Creates initial `TrainState`.\"\"\"\n",
    "    params = hypernetwork.init(rng, jnp.ones(input_shape))['params']\n",
    "    tx = optax.chain(\n",
    "        optax.clip_by_global_norm(10.0),\n",
    "        optax.adam(learning_rate),\n",
    "    )\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=hypernetwork.apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.partial(jax.jit, static_argnames=('apply_fn'))\n",
    "def train_step(apply_fn, state, observations, actions, discounted_rewards):\n",
    "    def loss_fn(params):\n",
    "        logits, _, _ = apply_fn({'params':params}, observations)\n",
    "        logits = jnp.array(logits)\n",
    "        dist = tfp.distributions.Categorical(logits=jnp.squeeze(logits))\n",
    "        log_probs = jnp.squeeze(dist.log_prob(actions))\n",
    "        loss = jnp.sum(discounted_rewards * log_probs)\n",
    "        return -1*loss\n",
    "    grad_fn = jax.value_and_grad(loss_fn)\n",
    "    loss, grads = grad_fn(state.params)\n",
    "    return state.apply_gradients(grads=grads), loss, grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "def get_tensorboard_logger(\n",
    "    experiment_name: str, base_log_path: str = \"tensorboard_logs\"\n",
    "):\n",
    "    log_path = \"{}/{}_{}\".format(base_log_path, experiment_name, datetime.now())\n",
    "    train_writer = SummaryWriter(log_path, flush_secs=10)\n",
    "    full_log_path = os.path.join(os.getcwd(), log_path)\n",
    "    print(\n",
    "        \"Follow tensorboard logs with: python -m tensorboard.main --logdir '{}'\".format(full_log_path)\n",
    "    )\n",
    "    return train_writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def flatten(d):\n",
    "    df = pd.json_normalize(d, sep='_')\n",
    "    return df.to_dict(orient='records')[0]\n",
    "\n",
    "def discount_reward(rews, gamma: float = 0.99):\n",
    "    n = len(rews)\n",
    "    rtgs = np.zeros_like(rews)\n",
    "    for i in reversed(range(n)):\n",
    "        rtgs[i] = rews[i] + gamma*(rtgs[i + 1] if i + 1 < n else 0)\n",
    "    return rtgs\n",
    "\n",
    "def reinforce(\n",
    "        num_epochs,\n",
    "        env,\n",
    "        hypernetwork,\n",
    "        seed: int = 0,\n",
    "        lr: float = 0.0001,\n",
    "        gamma: float = 0.99,\n",
    "    ):\n",
    "    writer = get_tensorboard_logger(\"HypernetworkJaxRL\")\n",
    "\n",
    "    rng = jax.random.PRNGKey(seed)\n",
    "    rng, init_rng = jax.random.split(rng)\n",
    "    state = create_train_state(init_rng, hypernetwork, lr, (1,8))\n",
    "\n",
    "    bar = tqdm.tqdm(np.arange(num_epochs))\n",
    "\n",
    "    try:\n",
    "        for i in bar:\n",
    "            observations, actions, rewards, _, num_steps = rollout(env, hypernetwork, state.params, seed=seed)\n",
    "            discounted_rewards = discount_reward(np.array(rewards), 1.0)\n",
    "            discounted_rewards = discounted_rewards - np.mean(discounted_rewards)\n",
    "            discounted_rewards = discounted_rewards / (\n",
    "                np.std(discounted_rewards) + 1e-10\n",
    "            )\n",
    "\n",
    "            observations = jnp.array(observations)\n",
    "            actions = jnp.array(actions)\n",
    "            discounted_rewards = jnp.array(discounted_rewards)\n",
    "\n",
    "            state, loss, grads = train_step(hypernetwork.apply, state, observations, actions, discounted_rewards)\n",
    "            grad_dict = {k:dict(grads[k]) for k in grads.keys()}\n",
    "            grad_dict = flatten(grad_dict)\n",
    "\n",
    "            grad_dict = {k: {kk: np.sum(vv).item() for kk, vv in v.items()}\n",
    "                        for k, v in grad_dict.items()}\n",
    "            grad_dict = flatten(grad_dict)\n",
    "\n",
    "            metrics = {\"loss\":loss.item(), \"rewards\":np.sum(rewards), \"num_steps\":num_steps, **grad_dict}\n",
    "\n",
    "            for key in metrics:\n",
    "                writer.add_scalar(key, metrics[key], i)\n",
    "\n",
    "            bar.set_description('Loss: {}, Sum Reward: {}'.format(loss.item(), np.sum(rewards)))\n",
    "        return hypernetwork, state\n",
    "    except KeyboardInterrupt as e:\n",
    "        return hypernetwork, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_network = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper = FlaxHyperNetwork.from_target(\n",
    "                target_network=target_network,\n",
    "                target_input_shape=(1,8),\n",
    "                embedding_module=CustomFlaxEmbeddingModule,\n",
    "                weight_generator=CustomFlaxWeightGenerator,\n",
    "                embedding_dim = 32,\n",
    "                num_embeddings = 512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlaxHyperNetwork(\n",
       "    # attributes\n",
       "    target_network = MLP()\n",
       "    target_input_shape = (1, 8)\n",
       "    target_treedef = PyTreeDef(CustomNode(<class 'flax.core.frozen_dict.FrozenDict'>[()], [{'params': {'Dense_0': {'bias': *, 'kernel': *}, 'Dense_1': {'bias': *, 'kernel': *}, 'Dense_2': {'kernel': *}}}]))\n",
       "    embedding_module = CustomFlaxEmbeddingModule\n",
       "    weight_generator = CustomFlaxWeightGenerator\n",
       "    embedding_dim = 32\n",
       "    num_embeddings = 512\n",
       "    hidden_dim = None\n",
       "    num_target_parameters = 69120\n",
       "    embedding_module_kwargs = {}\n",
       "    weight_generator_kwargs = {}\n",
       "    target_weight_shapes = [(256,), (8, 256), (256,), (256, 256), (256, 4)]\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"LunarLander-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Follow tensorboard logs with: python -m tensorboard.main --logdir '/home/shyam/Code/hyper-nn/notebooks/tensorboard_logs/HypernetworkJaxRL_2022-03-23 12:06:07.309747'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'embeddings' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_242117/348286950.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhyper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreinforce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_242117/1446808551.py\u001b[0m in \u001b[0;36mreinforce\u001b[0;34m(num_epochs, env, hypernetwork, seed, lr, gamma)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypernetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mdiscounted_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscount_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mdiscounted_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscounted_rewards\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscounted_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_242117/1127484838.py\u001b[0m in \u001b[0;36mrollout\u001b[0;34m(env, hypernetwork, hypernetwork_params, render, seed)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mrendereds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrendered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypernetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypernetwork_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 14 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_242117/1127484838.py\u001b[0m in \u001b[0;36msample_actions\u001b[0;34m(apply_fn, hypernetwork_params, obs, generated_params)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_argnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'apply_fn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msample_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypernetwork_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mapply_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mhypernetwork_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycanvas/lib/python3.9/site-packages/hypernn-0.1.0-py3.9.egg/hypernn/jax/hypernet.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, generated_params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     ) -> Tuple[jnp.array, List[jnp.array]]:\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycanvas/lib/python3.9/site-packages/hypernn-0.1.0-py3.9.egg/hypernn/jax/hypernet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, generated_params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mtarget_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mgenerated_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         )\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'embeddings' referenced before assignment"
     ]
    }
   ],
   "source": [
    "hyper, state = reinforce(100000, env, hyper, seed=10, lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Imports specifically so we can render outputs in Jupyter.\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def render_rollout(model, state):\n",
    "    fig = plt.figure(\"Animation\",figsize=(7,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    observations, actions, rewards, rendereds, num_steps = rollout(gym.make(\"LunarLander-v2\"), model, state.params, render=True)\n",
    "    frames = []\n",
    "    for r in rendereds:\n",
    "        frame = ax.imshow(r)\n",
    "        ax.axis('off')\n",
    "        frames.append([frame])\n",
    "    anim = animation.ArtistAnimation(fig, frames, interval=50, blit=True)\n",
    "    display(display_animation(anim, default_mode='loop'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_rollout(hyper, state)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d64cb66d3d902aa83000daa06ca958bef94bde318911a82aee5f8df2bb8934b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pycanvas')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
