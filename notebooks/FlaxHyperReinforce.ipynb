{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this to install dependencies for this notebook\n",
    "# !pip install gym\n",
    "# !pip install tqdm\n",
    "# !pip install tensorboard\n",
    "# !pip install matplotlib\n",
    "# !pip install JSAnimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this to enable jax gpu preallocation, might lead to memory issues\n",
    "\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypernn.jax.embedding_module import FlaxEmbeddingModule\n",
    "from hypernn.jax.weight_generator import FlaxWeightGenerator\n",
    "from hypernn.jax.hypernet import FlaxHyperNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Any\n",
    "\n",
    "class CustomFlaxEmbeddingModule(FlaxEmbeddingModule):\n",
    "    def setup(self):\n",
    "        self.embedding = nn.Embed(self.num_embeddings, self.embedding_dim)\n",
    "\n",
    "    def __call__(self, inp: Optional[Any] = None):\n",
    "        indices = jnp.arange(0, self.num_embeddings)\n",
    "        return self.embedding(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFlaxWeightGenerator(FlaxWeightGenerator):\n",
    "    def setup(self):\n",
    "        self.dense1 = nn.Dense(32)\n",
    "        self.dense2 = nn.Dense(self.hidden_dim)\n",
    "\n",
    "    def __call__(self, embedding: jnp.array, inp: Optional[Any] = None):\n",
    "        x = self.dense1(embedding)\n",
    "        x = nn.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(256)(x)\n",
    "        x = nn.tanh(x)\n",
    "        x = nn.Dense(256)(x)\n",
    "        x = nn.tanh(x)\n",
    "        x = nn.Dense(4, use_bias=False)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_probability.substrates import jax as tfp\n",
    "\n",
    "import jax\n",
    "import functools\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=('apply_fn'))\n",
    "def sample_actions(apply_fn, hypernetwork_params, obs):\n",
    "    out, _, _ =  apply_fn({'params':hypernetwork_params}, jnp.expand_dims(jnp.array(obs), 0))\n",
    "    return out\n",
    "\n",
    "def rollout(env, hypernetwork, hypernetwork_params, render=False, seed: int = 0) -> float:\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    observations, actions, rewards, rendereds = [], [], [], []\n",
    "    while not done:\n",
    "        rendered = None\n",
    "        if render:\n",
    "            rendered = env.render(mode=\"rgb_array\")\n",
    "            rendereds.append(rendered)\n",
    "\n",
    "        out = sample_actions(hypernetwork.apply, hypernetwork_params, obs)\n",
    "        out = jnp.squeeze(out)\n",
    "        dist = tfp.distributions.Categorical(logits=out)\n",
    "        rng = jax.random.PRNGKey(np.random.randint(0, 10**10))\n",
    "        action = dist.sample(seed=rng).item()\n",
    "        next_obs, r, done, _ = env.step(action)\n",
    "\n",
    "        observations.append(obs)\n",
    "        actions.append(action)\n",
    "        rewards.append(r)\n",
    "\n",
    "        obs = next_obs\n",
    "\n",
    "    num_steps = len(observations)\n",
    "    env.close()\n",
    "    return observations, actions, rewards, rendereds, num_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "def get_tensorboard_logger(\n",
    "    experiment_name: str, base_log_path: str = \"tensorboard_logs\"\n",
    "):\n",
    "    log_path = \"{}/{}_{}\".format(base_log_path, experiment_name, datetime.now())\n",
    "    train_writer = SummaryWriter(log_path, flush_secs=10)\n",
    "    full_log_path = os.path.join(os.getcwd(), log_path)\n",
    "    print(\n",
    "        \"Follow tensorboard logs with: tensorboard --logdir '{}'\".format(full_log_path)\n",
    "    )\n",
    "    return train_writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "from flax.training import train_state  # Useful dataclass to keep train state\n",
    "\n",
    "def create_train_state(rng, hypernetwork, learning_rate, input_shape):\n",
    "    \"\"\"Creates initial `TrainState`.\"\"\"\n",
    "    params = hypernetwork.init(rng, jnp.ones(input_shape))['params']\n",
    "    tx = optax.chain(\n",
    "        optax.clip_by_global_norm(10.0),\n",
    "        optax.adam(learning_rate),\n",
    "    )\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=hypernetwork.apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.partial(jax.jit, static_argnames=('apply_fn'))\n",
    "def train_step(apply_fn, state, observations, actions, discounted_rewards):\n",
    "    def loss_fn(params):\n",
    "        logits, _, _ = apply_fn({'params':params}, observations)\n",
    "        logits = jnp.array(logits)\n",
    "        dist = tfp.distributions.Categorical(logits=jnp.squeeze(logits))\n",
    "        log_probs = jnp.squeeze(dist.log_prob(actions))\n",
    "        loss = jnp.sum(discounted_rewards * log_probs)\n",
    "        return -1*loss\n",
    "    grad_fn = jax.value_and_grad(loss_fn)\n",
    "    loss, grads = grad_fn(state.params)\n",
    "    return state.apply_gradients(grads=grads), loss, grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "def get_tensorboard_logger(\n",
    "    experiment_name: str, base_log_path: str = \"tensorboard_logs\"\n",
    "):\n",
    "    log_path = \"{}/{}_{}\".format(base_log_path, experiment_name, datetime.now())\n",
    "    train_writer = SummaryWriter(log_path, flush_secs=10)\n",
    "    full_log_path = os.path.join(os.getcwd(), log_path)\n",
    "    print(\n",
    "        \"Follow tensorboard logs with: python -m tensorboard.main --logdir '{}'\".format(full_log_path)\n",
    "    )\n",
    "    return train_writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def flatten(d):\n",
    "    df = pd.json_normalize(d, sep='_')\n",
    "    return df.to_dict(orient='records')[0]\n",
    "\n",
    "def discount_reward(rews, gamma: float = 0.99):\n",
    "    n = len(rews)\n",
    "    rtgs = np.zeros_like(rews)\n",
    "    for i in reversed(range(n)):\n",
    "        rtgs[i] = rews[i] + gamma*(rtgs[i + 1] if i + 1 < n else 0)\n",
    "    return rtgs\n",
    "\n",
    "def reinforce(\n",
    "        num_epochs,\n",
    "        env,\n",
    "        hypernetwork,\n",
    "        seed: int = 0,\n",
    "        lr: float = 0.0001,\n",
    "        gamma: float = 0.99,\n",
    "    ):\n",
    "    writer = get_tensorboard_logger(\"HypernetworkJaxRL\")\n",
    "\n",
    "    rng = jax.random.PRNGKey(seed)\n",
    "    rng, init_rng = jax.random.split(rng)\n",
    "    state = create_train_state(init_rng, hypernetwork, lr, (1,8))\n",
    "\n",
    "    bar = tqdm.tqdm(np.arange(num_epochs))\n",
    "\n",
    "    try:\n",
    "        for i in bar:\n",
    "            observations, actions, rewards, _, num_steps = rollout(env, hypernetwork, state.params, seed=seed)\n",
    "            discounted_rewards = discount_reward(np.array(rewards), 1.0)\n",
    "            discounted_rewards = discounted_rewards - np.mean(discounted_rewards)\n",
    "            discounted_rewards = discounted_rewards / (\n",
    "                np.std(discounted_rewards) + 1e-10\n",
    "            )\n",
    "\n",
    "            observations = jnp.array(observations)\n",
    "            actions = jnp.array(actions)\n",
    "            discounted_rewards = jnp.array(discounted_rewards)\n",
    "\n",
    "            state, loss, grads = train_step(hypernetwork.apply, state, observations, actions, discounted_rewards)\n",
    "            grad_dict = {k:dict(grads[k]) for k in grads.keys()}\n",
    "            grad_dict = flatten(grad_dict)\n",
    "\n",
    "            grad_dict = {k: {kk: np.sum(vv).item() for kk, vv in v.items()}\n",
    "                        for k, v in grad_dict.items()}\n",
    "            grad_dict = flatten(grad_dict)\n",
    "\n",
    "            metrics = {\"loss\":loss.item(), \"rewards\":np.sum(rewards), \"num_steps\":num_steps, **grad_dict}\n",
    "\n",
    "            for key in metrics:\n",
    "                writer.add_scalar(key, metrics[key], i)\n",
    "\n",
    "            bar.set_description('Loss: {}, Sum Reward: {}'.format(loss.item(), np.sum(rewards)))\n",
    "        return hypernetwork, state\n",
    "    except KeyboardInterrupt as e:\n",
    "        return hypernetwork, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_network = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_target_parameters = FlaxHyperNetwork.count_params(target_network, (1,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_module = CustomFlaxEmbeddingModule.from_target(target_network, embedding_dim = 8, num_embeddings = 512, num_target_parameters=num_target_parameters, target_input_shape=(1,8))\n",
    "weight_generator = CustomFlaxWeightGenerator.from_target(target_network, embedding_dim = 8, num_embeddings = 512, num_target_parameters=num_target_parameters, target_input_shape=(1,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper = FlaxHyperNetwork(\n",
    "                target_input_shape=(1,8),\n",
    "                target_network=target_network,\n",
    "                embedding_module=embedding_module,\n",
    "                weight_generator=weight_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlaxHyperNetwork(\n",
       "    # attributes\n",
       "    target_input_shape = (1, 8)\n",
       "    target_network = MLP()\n",
       "    target_treedef = PyTreeDef(CustomNode(<class 'flax.core.frozen_dict.FrozenDict'>[()], [{'params': {'Dense_0': {'bias': *, 'kernel': *}, 'Dense_1': {'bias': *, 'kernel': *}, 'Dense_2': {'kernel': *}}}]))\n",
       "    embedding_module = CustomFlaxEmbeddingModule()\n",
       "    weight_generator = CustomFlaxWeightGenerator()\n",
       "    embedding_dim = 100\n",
       "    num_embeddings = 3\n",
       "    hidden_dim = None\n",
       "    target_weight_shapes = [(256,), (8, 256), (256,), (256, 256), (256, 4)]\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"LunarLander-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = jnp.zeros((1,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "\"CustomFlaxEmbeddingModule\" object has no attribute \"embedding\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_156224/802120116.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhyper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycanvas/lib/python3.9/site-packages/hypernn-0.1.0-py3.9.egg/hypernn/jax/hypernet.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     ) -> Tuple[jnp.array, List[jnp.array]]:\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycanvas/lib/python3.9/site-packages/hypernn-0.1.0-py3.9.egg/hypernn/jax/hypernet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     ):\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mparam_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_treedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         return (\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycanvas/lib/python3.9/site-packages/hypernn-0.1.0-py3.9.egg/hypernn/jax/hypernet.py\u001b[0m in \u001b[0;36mgenerate_params\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     ) -> List[jnp.array]:\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mparam_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_156224/1420258481.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pycanvas/lib/python3.9/site-packages/flax/linen/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    686\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m       raise AttributeError(\n\u001b[0m\u001b[1;32m    689\u001b[0m           f'\"{self.__class__.__name__}\" object has no attribute \"{name}\"')\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: \"CustomFlaxEmbeddingModule\" object has no attribute \"embedding\""
     ]
    }
   ],
   "source": [
    "hyper.init(jax.random.PRNGKey(0), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_target_parameters = FlaxHyperNetwork.count_params(hyper, (1,8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = hyper.init(jax.random.PRNGKey(0), jnp.ones((1, 8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper, state = reinforce(100000, env, hyper, seed=10, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Imports specifically so we can render outputs in Jupyter.\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def render_rollout(model, state):\n",
    "    fig = plt.figure(\"Animation\",figsize=(7,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    observations, actions, rewards, rendereds, num_steps = rollout(gym.make(\"LunarLander-v2\"), model, state.params, render=True)\n",
    "    frames = []\n",
    "    for r in rendereds:\n",
    "        frame = ax.imshow(r)\n",
    "        ax.axis('off')\n",
    "        frames.append([frame])\n",
    "    anim = animation.ArtistAnimation(fig, frames, interval=50, blit=True)\n",
    "    display(display_animation(anim, default_mode='loop'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_rollout(hyper, state)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d64cb66d3d902aa83000daa06ca958bef94bde318911a82aee5f8df2bb8934b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pycanvas')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
