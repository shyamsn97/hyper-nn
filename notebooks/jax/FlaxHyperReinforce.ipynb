{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this to install dependencies for this notebook\n",
    "# !pip install gym\n",
    "# !pip install tqdm\n",
    "# !pip install tensorboard\n",
    "# !pip install matplotlib\n",
    "# !pip install JSAnimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this to enable jax gpu preallocation, might lead to memory issues\n",
    "\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypernn.jax.embedding_module import FlaxEmbeddingModule\n",
    "from hypernn.jax.weight_generator import FlaxWeightGenerator\n",
    "from hypernn.jax.hypernet import FlaxHyperNetwork\n",
    "from hypernn.jax.utils import count_jax_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Any, Dict\n",
    "\n",
    "class CustomFlaxEmbeddingModule(FlaxEmbeddingModule):\n",
    "    def setup(self):\n",
    "        self.embedding = nn.Embed(self.num_embeddings, self.embedding_dim)\n",
    "\n",
    "    def __call__(self, inp: Optional[Any] = None):\n",
    "        indices = jnp.arange(0, self.num_embeddings)\n",
    "        return {\"embedding\":self.embedding(indices)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFlaxWeightGenerator(FlaxWeightGenerator):\n",
    "    def setup(self):\n",
    "        self.dense1 = nn.Dense(32)\n",
    "        self.dense2 = nn.Dense(self.hidden_dim, use_bias=False)\n",
    "\n",
    "    def __call__(self, embedding_module_output: Dict[str, jnp.array], inp: Optional[Any] = None):\n",
    "        x = self.dense1(embedding_module_output[\"embedding\"])\n",
    "        x = nn.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        return {\"params\":x.reshape(-1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(256, use_bias=True)(x)\n",
    "        x = nn.tanh(x)\n",
    "        x = nn.Dense(256, use_bias=True)(x)\n",
    "        x = nn.tanh(x)\n",
    "        x = nn.Dense(4, use_bias=False)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_probability.substrates import jax as tfp\n",
    "\n",
    "import jax\n",
    "import functools\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=('apply_fn', 'method'))\n",
    "def generate_params(apply_fn, hypernetwork_params, method):\n",
    "    generated_params, embedding_module_output, weight_generator_output = apply_fn({'params':hypernetwork_params}, method=method)\n",
    "    return generated_params\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=('apply_fn'))\n",
    "def sample_actions(apply_fn, hypernetwork_params, obs, generated_params):\n",
    "    out =  apply_fn({'params':hypernetwork_params}, inp=[jnp.expand_dims(jnp.array(obs), 0)], generated_params=generated_params, has_aux=False)\n",
    "    # out = jnp.squeeze(out)\n",
    "    # dist = tfp.distributions.Categorical(logits=out, allow_nan_stats=False)\n",
    "    # seed = np.random.randint(0, 100000)\n",
    "    # rng = jax.random.PRNGKey(seed)\n",
    "    # action = dist.sample(seed=rng)\n",
    "    # return action\n",
    "    return out\n",
    "\n",
    "def rollout(env, apply_fn, generate_params_fn, hypernetwork_params, render=False, seed: int = 0) -> float:\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    observations, actions, rewards, rendereds = [], [], [], []\n",
    "    generated_params = generate_params(apply_fn, hypernetwork_params, generate_params_fn)\n",
    "    while not done:\n",
    "        rendered = None\n",
    "        if render:\n",
    "            rendered = env.render(mode=\"rgb_array\")\n",
    "            rendereds.append(rendered)\n",
    "\n",
    "        out = sample_actions(apply_fn, hypernetwork_params, obs, generated_params)\n",
    "        out = jnp.squeeze(out)\n",
    "        dist = tfp.distributions.Categorical(logits=out)\n",
    "        rng = jax.random.PRNGKey(np.random.randint(0, 10**10))\n",
    "        action = dist.sample(seed=rng).item()\n",
    "\n",
    "        next_obs, r, done, _ = env.step(action)\n",
    "\n",
    "        observations.append(obs)\n",
    "        actions.append(action)\n",
    "        rewards.append(r)\n",
    "\n",
    "        obs = next_obs\n",
    "\n",
    "    num_steps = len(observations)\n",
    "    env.close()\n",
    "    return observations, actions, rewards, rendereds, num_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "from flax.training import train_state  # Useful dataclass to keep train state\n",
    "\n",
    "def create_train_state(rng, hypernetwork, learning_rate, input_shape):\n",
    "    \"\"\"Creates initial `TrainState`.\"\"\"\n",
    "    params = hypernetwork.init(rng, [jnp.ones(input_shape)])['params']\n",
    "    # Exponential decay of the learning rate.\n",
    "    scheduler = optax.exponential_decay(\n",
    "        init_value=learning_rate, \n",
    "        transition_steps=1000,\n",
    "        decay_rate=0.99)\n",
    "\n",
    "    tx = optax.chain(\n",
    "        optax.clip_by_global_norm(10.0),\n",
    "        # optax.scale_by_adam(),  # Use the updates from adam.\n",
    "        # optax.scale_by_schedule(scheduler),  # Use the learning rate from the scheduler.\n",
    "        # # Scale updates by -1 since optax.apply_updates is additive and we want to descend on the loss.\n",
    "        # optax.scale(-1.0)\n",
    "        optax.adam(learning_rate)\n",
    "    )\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=hypernetwork.apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.partial(jax.jit, static_argnames=('apply_fn'))\n",
    "def train_step(apply_fn, state, observations, actions, discounted_rewards):\n",
    "    def loss_fn(params):\n",
    "        logits = apply_fn({'params':params}, inp=[observations], has_aux=False)\n",
    "        dist = tfp.distributions.Categorical(logits=jnp.squeeze(logits))\n",
    "        log_probs = jnp.squeeze(dist.log_prob(actions))\n",
    "        loss = jnp.sum(discounted_rewards * log_probs)\n",
    "        return -1*loss\n",
    "    grad_fn = jax.value_and_grad(loss_fn)\n",
    "    loss, grads = grad_fn(state.params)\n",
    "    return state.apply_gradients(grads=grads), loss, grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "def get_tensorboard_logger(\n",
    "    experiment_name: str, base_log_path: str = \"tensorboard_logs\"\n",
    "):\n",
    "    log_path = \"{}/{}_{}\".format(base_log_path, experiment_name, datetime.now())\n",
    "    train_writer = SummaryWriter(log_path, flush_secs=10)\n",
    "    full_log_path = os.path.join(os.getcwd(), log_path)\n",
    "    print(\n",
    "        \"Follow tensorboard logs with: python -m tensorboard.main --logdir '{}'\".format(full_log_path)\n",
    "    )\n",
    "    return train_writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "def flatten(d):\n",
    "    df = pd.json_normalize(d, sep='_')\n",
    "    return df.to_dict(orient='records')[0]\n",
    "\n",
    "def discount_reward(rews, gamma: float = 0.99):\n",
    "    n = len(rews)\n",
    "    rtgs = np.zeros_like(rews)\n",
    "    for i in reversed(range(n)):\n",
    "        rtgs[i] = rews[i] + gamma*(rtgs[i + 1] if i + 1 < n else 0)\n",
    "    return rtgs\n",
    "\n",
    "def reinforce(\n",
    "        num_epochs,\n",
    "        env,\n",
    "        hypernetwork,\n",
    "        seed: int = 0,\n",
    "        lr: float = 0.0001,\n",
    "        gamma: float = 0.99,\n",
    "    ):\n",
    "    writer = get_tensorboard_logger(\"HypernetworkJaxRL\")\n",
    "\n",
    "    rng = jax.random.PRNGKey(seed)\n",
    "    rng, init_rng = jax.random.split(rng)\n",
    "    state = create_train_state(init_rng, hypernetwork, lr, (1,8))\n",
    "\n",
    "    bar = tqdm.tqdm(np.arange(num_epochs))\n",
    "\n",
    "    try:\n",
    "        for i in bar:\n",
    "            observations, actions, rewards, _, num_steps = rollout(env, hypernetwork.apply, hypernetwork.generate_params, state.params, seed=seed)\n",
    "            discounted_rewards = discount_reward(np.array(rewards), 0.99)\n",
    "            discounted_rewards = discounted_rewards - np.mean(discounted_rewards)\n",
    "            discounted_rewards = discounted_rewards / (\n",
    "                np.std(discounted_rewards) + 1e-10\n",
    "            )\n",
    "\n",
    "            observations = jnp.array(observations)\n",
    "            actions = jnp.array(actions)\n",
    "            discounted_rewards = jnp.array(discounted_rewards)\n",
    "\n",
    "            state, loss, grads = train_step(hypernetwork.apply, state, observations, actions, discounted_rewards)\n",
    "            grad_dict = {k:dict(grads[k]) for k in grads.keys()}\n",
    "            grad_dict = flatten(grad_dict)\n",
    "\n",
    "            grad_dict = {k: {kk: np.sum(vv).item() for kk, vv in v.items()}\n",
    "                        for k, v in grad_dict.items()}\n",
    "            grad_dict = flatten(grad_dict)\n",
    "\n",
    "            metrics = {\"loss\":loss.item(), \"rewards\":np.sum(rewards), \"num_steps\":num_steps, **grad_dict}\n",
    "\n",
    "            for key in metrics:\n",
    "                writer.add_scalar(key, metrics[key], i)\n",
    "\n",
    "            bar.set_description('Loss: {}, Sum Reward: {}'.format(loss.item(), np.sum(rewards)))\n",
    "        return hypernetwork, state\n",
    "    except KeyboardInterrupt as e:\n",
    "        return hypernetwork, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69120"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_network = MLP()\n",
    "\n",
    "count_jax_params(target_network, inputs=jnp.zeros((1,8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21760"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper = FlaxHyperNetwork.from_target(\n",
    "                target_network=target_network,\n",
    "                target_input_shape=[(1,8)],\n",
    "                embedding_module=CustomFlaxEmbeddingModule,\n",
    "                weight_generator=CustomFlaxWeightGenerator,\n",
    "                embedding_dim = 32,\n",
    "                num_embeddings = 512\n",
    ")\n",
    "count_jax_params(hyper, inputs=[jnp.zeros((1,8))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlaxHyperNetwork(\n",
       "    # attributes\n",
       "    target_network = MLP()\n",
       "    target_input_shape = [(1, 8)]\n",
       "    target_treedef = PyTreeDef(CustomNode(<class 'flax.core.frozen_dict.FrozenDict'>[()], [{'params': {'Dense_0': {'bias': *, 'kernel': *}, 'Dense_1': {'bias': *, 'kernel': *}, 'Dense_2': {'kernel': *}}}]))\n",
       "    embedding_module = CustomFlaxEmbeddingModule\n",
       "    weight_generator = CustomFlaxWeightGenerator\n",
       "    embedding_dim = 32\n",
       "    num_embeddings = 512\n",
       "    hidden_dim = None\n",
       "    num_target_parameters = 69120\n",
       "    embedding_module_kwargs = {}\n",
       "    weight_generator_kwargs = {}\n",
       "    target_weight_shapes = [(256,), (8, 256), (256,), (256, 256), (256, 4)]\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"LunarLander-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Follow tensorboard logs with: python -m tensorboard.main --logdir '/home/shyam/Code/hyper-nn/notebooks/jax/tensorboard_logs/HypernetworkJaxRL_2022-04-07 14:27:52.947233'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: -67.25050354003906, Sum Reward: 222.75297797490637:   2%|▏         | 1736/100000 [50:01<47:11:27,  1.73s/it]   \n"
     ]
    }
   ],
   "source": [
    "hyper, state = reinforce(100000, env, hyper, seed=10, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib ipympl\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "# Imports specifically so we can render outputs in Jupyter.\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "from celluloid import Camera\n",
    "from IPython.display import HTML\n",
    "\n",
    "# def rollout(env, apply_fn, generate_params_fn, hypernetwork_params, render=False, seed: int = 0) -> float:\n",
    "\n",
    "def render_rollout(model, state):\n",
    "    fig = plt.figure(\"Animation\",figsize=(7,5))\n",
    "    camera = Camera(fig)\n",
    "    ax = fig.add_subplot(111)\n",
    "    observations, actions, rewards, rendereds, num_steps = rollout(gym.make(\"LunarLander-v2\"), model.apply, model.generate_params, state.params, render=True)\n",
    "    frames = []\n",
    "    for r in rendereds:\n",
    "        frame = ax.imshow(r)\n",
    "        ax.axis('off')\n",
    "        camera.snap()\n",
    "        frames.append([frame])\n",
    "    animation = camera.animate(blit=False, interval=50)\n",
    "    # display(animations.to_html5_video())\n",
    "    animation.save('lunar_lander.mp4')\n",
    "    return animation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "setup() got an unexpected keyword argument 'clear_temp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40214/923157136.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrender_rollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_40214/2520851883.py\u001b[0m in \u001b[0;36mrender_rollout\u001b[0;34m(model, state)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0manim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manimation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArtistAnimation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay_animation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pycanvas/lib/python3.9/site-packages/JSAnimation/IPython_display.py\u001b[0m in \u001b[0;36mdisplay_animation\u001b[0;34m(anim, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;34m\"\"\"Display the animation with an IPython HTML object\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manim_to_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycanvas/lib/python3.9/site-packages/JSAnimation/IPython_display.py\u001b[0m in \u001b[0;36manim_to_html\u001b[0;34m(anim, fps, embed_frames, default_mode)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m#with tempfile.NamedTemporaryFile(suffix='.html') as f:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_NameOnlyTemporaryFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.html'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             anim.save(f.name,  writer=HTMLWriter(fps=fps,\n\u001b[0m\u001b[1;32m     75\u001b[0m                                                  \u001b[0membed_frames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membed_frames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                                                  default_mode=default_mode))\n",
      "\u001b[0;32m~/anaconda3/envs/pycanvas/lib/python3.9/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0;31m# callback a no-op; canvas.manager = None prevents resizing the GUI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0;31m# widget (both are likewise done in savefig()).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrc_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'savefig.bbox'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m              \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m              cbook._setattr_cm(self._fig.canvas,\n",
      "\u001b[0;32m~/anaconda3/envs/pycanvas/lib/python3.9/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycanvas/lib/python3.9/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msaving\u001b[0;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \"\"\"\n\u001b[1;32m    233\u001b[0m         \u001b[0;31m# This particular sequence is what contextlib.contextmanager wants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycanvas/lib/python3.9/site-packages/JSAnimation/html_writer.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, fig, outfile, dpi, frame_dir)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mframe_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         super(HTMLWriter, self).setup(fig, outfile, dpi,\n\u001b[0m\u001b[1;32m    282\u001b[0m                                       frame_prefix, clear_temp=False)\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: setup() got an unexpected keyword argument 'clear_temp'"
     ]
    }
   ],
   "source": [
    "_ = render_rollout(hyper, state)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d64cb66d3d902aa83000daa06ca958bef94bde318911a82aee5f8df2bb8934b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pycanvas')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
