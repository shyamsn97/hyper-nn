{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Hyper MNIST"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Loading MNIST"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "## load mnist dataset\n",
    "\n",
    "root = 'data'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "\n",
    "trans = transforms.Compose([transforms.ToTensor()])\n",
    "# if not exist, download mnist dataset\n",
    "train_set = torchvision.datasets.MNIST(root=root, train=True, transform=trans, download=True)\n",
    "test_set = torchvision.datasets.MNIST(root=root, train=False, transform=trans, download=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "train_set[0][0].size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(train_set[i][0].detach().numpy().squeeze(), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(train_set[i][1]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import torch\n",
    "\n",
    "class TorchMNISTConvNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 512, 3, 2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(512, 512, 3, 2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(512, 512, 3, 2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(512, 10, 2, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x).view(x.size(0), -1)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "torch_target_network = TorchMNISTConvNet()\n",
    "pytorch_total_params = sum(p.numel() for p in torch_target_network.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4745226"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "torch_target_network(torch.zeros(1,1,28,28)).size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Torch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from hypernn.torch.static_hypernet import TorchHyperNetwork\n",
    "from typing import Any, Optional"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Simple Embedding Module + Weight Generator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instantiating hypernetwork with Class definitions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "hypernetwork = TorchHyperNetwork.from_target(\n",
    "    torch_target_network,\n",
    "    embedding_dim=4,\n",
    "    num_embeddings=1024\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import torch.nn as nn\n",
    "from typing import Tuple, Dict, Optional\n",
    "\n",
    "class RecursiveHyperNetwork(TorchHyperNetwork):\n",
    "    def __init__(\n",
    "        self,\n",
    "        target_network: nn.Module,\n",
    "        num_target_parameters: Optional[int] = None,\n",
    "        embedding_dim: int = 100,\n",
    "        num_embeddings: int = 3,\n",
    "        hidden_dim: Optional[int] = None,\n",
    "        *args, **kwargs\n",
    "    ):\n",
    "        super().__init__(\n",
    "                    target_network = target_network,\n",
    "                    num_target_parameters = num_target_parameters,\n",
    "                    embedding_dim = embedding_dim,\n",
    "                    num_embeddings = num_embeddings,\n",
    "                    hidden_dim = hidden_dim,\n",
    "                )\n",
    "        self.layer_norm = nn.LayerNorm([self.hidden_dim])\n",
    "\n",
    "    def make_weight_generator(self):\n",
    "        return nn.Linear(self.embedding_dim, self.hidden_dim, bias=False)\n",
    "\n",
    "    def generate_params(\n",
    "        self, inp = []\n",
    "    ) -> Tuple[torch.Tensor, Dict[str, Any]]:\n",
    "        embedding = self.embedding(torch.arange(self.num_embeddings).to(self.device))\n",
    "        generated_params = self.weight_generator(embedding / embedding.max()).view(-1)\n",
    "        return generated_params, {\"embedding\": embedding}\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def hyper_hyper(num_levels: int, target_network, embedding_dim, num_embeddings):\n",
    "    t = target_network\n",
    "    for i in range(num_levels - 1):\n",
    "        hypernetwork = RecursiveHyperNetwork.from_target(\n",
    "                    t,\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_embeddings=num_embeddings\n",
    "        )\n",
    "        t = hypernetwork\n",
    "    hypernetwork = RecursiveHyperNetwork.from_target(\n",
    "                t,\n",
    "                embedding_dim=4,\n",
    "                num_embeddings=num_embeddings\n",
    "    )\n",
    "    return hypernetwork"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "class HyperHyper(nn.Module):\n",
    "    def __init__(self, num_levels, target_network, embedding_dim, num_embeddings):\n",
    "        super().__init__()\n",
    "        self.num_levels = num_levels\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.hypernetwork = hyper_hyper(num_levels, target_network, embedding_dim, num_embeddings)\n",
    "\n",
    "    def forward(self, x):\n",
    "        inp = x.to(self.hypernetwork.device)\n",
    "        for i in range(self.num_levels - 1):\n",
    "                inp = [inp]\n",
    "        return self.hypernetwork(inp=[inp])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "hypernetwork = HyperHyper(6, torch_target_network, 4, 32)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "pytorch_total_params = sum(p.numel() for p in hypernetwork.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "hypernetwork(torch.zeros((1,1,28,28)))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.0054,  0.0036,  0.0055, -0.0052,  0.0102, -0.0457,  0.0027, -0.0193,\n",
       "         -0.0070,  0.0094]], grad_fn=<ViewBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=32,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=32,\n",
    "                shuffle=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train hypernetwork"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "def get_tensorboard_logger(\n",
    "    experiment_name: str, base_log_path: str = \"tensorboard_logs\"\n",
    "):\n",
    "    log_path = \"{}/{}_{}\".format(base_log_path, experiment_name, datetime.now())\n",
    "    train_writer = SummaryWriter(log_path, flush_secs=10)\n",
    "    full_log_path = os.path.join(os.getcwd(), log_path)\n",
    "    print(\n",
    "        \"Follow tensorboard logs with: python -m tensorboard.main --logdir '{}'\".format(full_log_path)\n",
    "    )\n",
    "    return train_writer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Follow tensorboard logs with: python -m tensorboard.main --logdir '/home/shyam/Code/hyper-nn/notebooks/tensorboard_logs/HypernetworkTorchRL_2022-04-26 17:06:53.438081'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9432039260864258, Test Acc: 0.6363000273704529: 100%|██████████| 1000/1000 [5:59:45<00:00, 21.59s/it]  \n"
     ]
    }
   ],
=======
   "execution_count": 20,
>>>>>>> 03abdbfeecc3dd4b12c892817664cb634c041971
   "source": [
    "def random_sample(dataset, num_samples:int = 1):\n",
    "    length = len(dataset)\n",
    "    random_indices = np.random.randint(0,length, num_samples)\n",
    "    return torch.stack([dataset[idx][0] for idx in random_indices]), torch.tensor([dataset[idx][1] for idx in random_indices])\n",
    "\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=32,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=32,\n",
    "                shuffle=False)\n",
    "\n",
    "writer = get_tensorboard_logger(\"HypernetworkTorchRL\")\n",
    "\n",
    "hypernetwork = HyperHyper(6, torch_target_network, 4, 32)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "hypernetwork = hypernetwork.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(hypernetwork.parameters(), lr=0.02)\n",
    "bar = tqdm.tqdm(np.arange(100000))\n",
    "\n",
    "grad_dict = {}\n",
    "\n",
    "for i in bar:\n",
    "\n",
    "    train_loss = []\n",
    "    x, target = random_sample(train_set, 512)\n",
    "    x = x.to(device)\n",
    "    target = target.to(device)\n",
    "    # for batch_idx, (x, target) in enumerate(train_loader):\n",
    "    # for sample in samples:\n",
    "    optimizer.zero_grad()\n",
    "    out = hypernetwork(x)\n",
    "    loss =  torch.nn.functional.cross_entropy(out, target)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(hypernetwork.parameters(), 10.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    train_loss.append(loss.item())\n",
    "\n",
    "    avg_loss = np.mean(train_loss)\n",
    "\n",
    "    num_correct = 0\n",
    "    count = 0\n",
    "    for batch_idx, (x, target) in enumerate(test_loader):\n",
    "        count += x.size(0)\n",
    "        with torch.no_grad():\n",
    "            out = hypernetwork(x.to(device))\n",
    "            _, predicted = torch.max(out.detach(), -1)\n",
    "        num_correct += (predicted.detach().cpu() == target.data).sum()\n",
    "    accuracy = num_correct / count\n",
    "\n",
    "    grad_dict = {}\n",
    "    for n, W in hypernetwork.named_parameters():\n",
    "        if W.grad is not None:\n",
    "            grad_dict[\"{}_grad\".format(n)] = float(torch.sum(W.grad).item())\n",
    "\n",
    "    metrics = {\"loss\":loss.item(), \"accuracy\":accuracy.item(), **grad_dict}\n",
    "\n",
    "    for key in metrics:\n",
    "        writer.add_scalar(key, metrics[key], i)\n",
    "\n",
    "    bar.set_description(\"Loss: {}, Test Acc: {}\".format(avg_loss, accuracy))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Follow tensorboard logs with: python -m tensorboard.main --logdir '/home/kokkgoblin/Code/hyper-nn/notebooks/tensorboard_logs/HypernetworkTorchRL_2022-04-29 11:18:02.819175'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loss: 0.4020153880119324, Test Acc: 0.8939999938011169:  15%|█▍        | 14565/100000 [9:04:31<53:21:27,  2.25s/it]"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Display subset of predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    out = hypernetwork(test_set[i][0].to(device))\n",
    "    _, predicted = torch.max(out.detach(), -1)\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(test_set[i][0].detach().numpy().squeeze(), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Prediction: {}\".format(predicted.item()))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LSTM Hypernetwork"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "from typing import Any, Dict, List, Optional, Tuple, Type, Union  # noqa\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMHypernetwork(TorchHyperNetwork):\n",
    "    def __init__(\n",
    "        self,\n",
    "        target_network: nn.Module,\n",
    "        num_target_parameters: Optional[int] = None,\n",
    "        embedding_dim: int = 100,\n",
    "        num_embeddings: int = 3,\n",
    "        hidden_dim: Optional[int] = None,\n",
    "        *args, **kwargs\n",
    "    ):\n",
    "        super().__init__(\n",
    "                    target_network = target_network,\n",
    "                    num_target_parameters = num_target_parameters,\n",
    "                    embedding_dim = embedding_dim,\n",
    "                    num_embeddings = num_embeddings,\n",
    "                    hidden_dim = hidden_dim,\n",
    "                )\n",
    "\n",
    "    def make_embedding(self):\n",
    "        embedding = nn.Parameter(torch.randn(1, self.embedding_dim).to(self.device))\n",
    "        return embedding\n",
    "\n",
    "    def make_weight_generator(self):\n",
    "        return nn.GRUCell(self.embedding_dim, self.hidden_dim)\n",
    "\n",
    "    def generate_params(\n",
    "        self, inp = []\n",
    "    ) -> Tuple[torch.Tensor, Dict[str, Any]]:\n",
    "        embedding = self.embedding\n",
    "        hidden = torch.zeros(1, self.hidden_dim, device=self.device)\n",
    "        output = []\n",
    "        for _ in range(self.num_embeddings):\n",
    "            hidden = self.weight_generator(embedding, hidden)\n",
    "            output.append(hidden)\n",
    "        return torch.stack(output).view(-1), {}\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "hypernetwork = LSTMHypernetwork.from_target(\n",
    "    torch_target_network,\n",
    "    embedding_dim=8,\n",
    "    num_embeddings=7000\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "pytorch_total_params = sum(p.numel() for p in hypernetwork.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "hypernetwork(inp=[torch.zeros((1,1,28,28), device=hypernetwork.device)])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.0585, -0.3283,  0.7292, -0.5671, -0.0905, -0.7228, -0.0016, -0.0040,\n",
       "         -0.3661,  0.2521]], device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "device = torch.device('cuda')\n",
    "hypernetwork = hypernetwork.to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "len(train_set)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "np.random.randint(0,100, 5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([67, 74, 83, 90, 54])"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "def random_sample(dataset, num_samples:int = 1):\n",
    "    length = len(dataset)\n",
    "    random_indices = np.random.randint(0,length, num_samples)\n",
    "    return [dataset[idx] for idx in random_indices]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "num_samples = 1\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=32,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=32,\n",
    "                shuffle=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(hypernetwork.parameters(), lr=0.001)\n",
    "bar = tqdm.tqdm(np.arange(1000))\n",
    "\n",
    "for i in bar:\n",
    "\n",
    "    train_loss = []\n",
    "    samples = random_sample(train_set, num_samples)\n",
    "    for sample in samples:\n",
    "        x = sample[0].view(1, 1, 28, 28).to(hypernetwork.device)\n",
    "        target = torch.tensor(sample[1]).view(1,).to(hypernetwork.device)\n",
    "        optimizer.zero_grad()\n",
    "        out = hypernetwork(inp=[x.to(hypernetwork.device)], has_aux=False)\n",
    "        loss =  torch.nn.functional.cross_entropy(out.to(hypernetwork.device), target.to(hypernetwork.device))\n",
    "        print(\"SHIT\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "    avg_loss = np.mean(train_loss)\n",
    "    num_correct = 0\n",
    "    count = 0\n",
    "    for batch_idx, (x, target) in enumerate(test_loader):\n",
    "        count += x.size(0)\n",
    "        with torch.no_grad():\n",
    "            out = hypernetwork(inp=[x.to(hypernetwork.device)], has_aux=False)\n",
    "            _, predicted = torch.max(out.detach(), -1)\n",
    "        num_correct += (predicted.detach().cpu() == target.data).sum()\n",
    "    accuracy = num_correct / count\n",
    "    bar.set_description(\"Loss: {}, Test Acc: {}\".format(avg_loss, accuracy))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SHIT\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loss: 2.03393292427063, Test Acc: 0.10329999774694443:   0%|          | 1/1000 [01:34<26:19:02, 94.84s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SHIT\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loss: 2.2978427410125732, Test Acc: 0.10320000350475311:   0%|          | 2/1000 [03:08<26:02:35, 93.94s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SHIT\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loss: 2.2978427410125732, Test Acc: 0.10320000350475311:   0%|          | 2/1000 [03:43<31:00:24, 111.85s/it]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_90591/903286999.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhypernetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypernetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mnum_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycanvas/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycanvas/lib/python3.9/site-packages/hypernn-0.1.0-py3.9.egg/hypernn/torch/hypernet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, generated_params, has_aux, *args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0maux_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgenerated_params\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mgenerated_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_90591/2128266366.py\u001b[0m in \u001b[0;36mgenerate_params\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycanvas/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycanvas/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRUCell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_chunks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfactory_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0;34mf\"GRUCell: Expected input to be 1-D or 2-D but received {input.dim()}-D tensor\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Jax"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# uncomment this to enable jax gpu preallocation, might lead to memory issues\n",
    "\n",
    "import os\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import flax.linen as linen"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class JaxMNISTConvNet(linen.Module):\n",
    "\n",
    "    @linen.compact\n",
    "    def __call__(self, x):\n",
    "        x = linen.Conv(64, kernel_size=(3,3), strides=2, padding=\"VALID\")(x)\n",
    "        x = linen.relu(x)\n",
    "        x = linen.Conv(64, kernel_size=(3,3), strides=2, padding=\"VALID\")(x)\n",
    "        x = linen.relu(x)\n",
    "        x = linen.Conv(64, kernel_size=(3,3), strides=2, padding=\"VALID\")(x)\n",
    "        x = linen.relu(x)\n",
    "        x = linen.Conv(10, kernel_size=(2,2), strides=2, padding=\"VALID\")(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = linen.log_softmax(x)\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "jax_target_network = JaxMNISTConvNet()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from hypernn.jax.utils import count_jax_params\n",
    "\n",
    "count_jax_params(jax_target_network, inputs=[jnp.zeros((64,64,1))])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Simple Jax Hypernetwork"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from typing import Optional, Any, Dict\n",
    "\n",
    "from hypernn.jax.embedding_module import FlaxEmbeddingModule\n",
    "from hypernn.jax.weight_generator import FlaxWeightGenerator\n",
    "from hypernn.jax.hypernet import FlaxHyperNetwork\n",
    "\n",
    "\n",
    "class CustomFlaxEmbeddingModule(FlaxEmbeddingModule):\n",
    "    def setup(self):\n",
    "        self.embedding = linen.Embed(self.num_embeddings, self.embedding_dim)\n",
    "\n",
    "    def __call__(self, inp: Optional[Any] = None):\n",
    "        indices = jnp.arange(0, self.num_embeddings)\n",
    "        return self.embedding(indices), {}\n",
    "\n",
    "class CustomFlaxWeightGenerator(FlaxWeightGenerator):\n",
    "    def setup(self):\n",
    "        self.dense1 = linen.Dense(32)\n",
    "        self.dense2 = linen.Dense(self.hidden_dim, use_bias=False)\n",
    "\n",
    "    def __call__(self, embedding, inp: Optional[Any] = None):\n",
    "        x = self.dense1(embedding)\n",
    "        x = linen.tanh(x)\n",
    "        x = self.dense2(x)\n",
    "        return x.reshape(-1), {}\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Making hypernetwork with `embedding_dim = 4` and `num_embeddings = 1024`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "jax_hyper = FlaxHyperNetwork.from_target(\n",
    "    target_network=jax_target_network,\n",
    "    inputs=[jnp.zeros((28,28,1))],\n",
    "    embedding_module=CustomFlaxEmbeddingModule,\n",
    "    weight_generator=CustomFlaxWeightGenerator,\n",
    "    embedding_dim = 4,\n",
    "    num_embeddings = 1024\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "count_jax_params(jax_hyper, inputs=[[jnp.zeros((28,28,1))]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training MNIST"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Creating train state"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import optax\n",
    "from flax.training import train_state  # Useful dataclass to keep train state\n",
    "\n",
    "def create_hyper_train_state(rng, model, learning_rate):\n",
    "    \"\"\"Creates initial `TrainState`.\"\"\"\n",
    "    params = model.init(rng, [jnp.zeros((28,28,1))])['params']\n",
    "    tx = optax.chain(\n",
    "        optax.adam(learning_rate)\n",
    "    )\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=model.apply, params=params, tx=tx\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Update step"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def cross_entropy_loss(logits, labels):\n",
    "    one_hot_labels = jax.nn.one_hot(labels, num_classes=10)\n",
    "    return -jnp.mean(jnp.sum(one_hot_labels * logits, axis=-1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import functools\n",
    "\n",
    "@jax.jit\n",
    "def compute_metrics(logits, labels):\n",
    "    loss = cross_entropy_loss(logits=logits, labels=labels)\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "    metrics = {\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=('apply_fn'))\n",
    "def train_step(apply_fn, state, x, targets):\n",
    "    \"\"\"Train for a single step.\"\"\"\n",
    "    def loss_fn(params):\n",
    "        logits = apply_fn({'params': params}, inp=[x], has_aux=False)\n",
    "        loss = cross_entropy_loss(logits=logits, labels=targets)\n",
    "        return loss, logits\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (_, logits), grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    metrics = compute_metrics(logits=logits, labels=targets)\n",
    "    return state, metrics"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "\n",
    "bar = tqdm.tqdm(np.arange(1000))\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "state = create_hyper_train_state(rng, jax_hyper, 0.0002)\n",
    "\n",
    "for i in bar:\n",
    "\n",
    "    train_loss = []\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        x = rearrange(jnp.array(x.numpy()), 'b c w h -> b w h c')\n",
    "        target = jnp.array(target.numpy())\n",
    "\n",
    "        state, metrics = train_step(jax_hyper.apply, state, x, target)\n",
    "        loss = metrics[\"loss\"]\n",
    "        # optimizer.zero_grad()\n",
    "        # out = hypernetwork(inp=[x.to(hypernetwork.device)], has_aux=False)\n",
    "        # loss =  torch.nn.functional.cross_entropy(out.to(hypernetwork.device), target.to(hypernetwork.device))\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "    avg_loss = np.mean(train_loss)\n",
    "    num_correct = 0\n",
    "    count = 0\n",
    "    for batch_idx, (x, target) in enumerate(test_loader):\n",
    "        x = rearrange(jnp.array(x.numpy()), 'b c w h -> b w h c')\n",
    "        count += x.shape[0]\n",
    "        logits = jax_hyper.apply({\"params\":state.params}, inp=[x], has_aux=False)\n",
    "        # with torch.no_grad():\n",
    "        #     out = hypernetwork(inp=[x.to(hypernetwork.device)], has_aux=False)\n",
    "        #     _, predicted = torch.max(out.detach(), -1)\n",
    "        num_correct += jnp.sum(jnp.argmax(logits, -1) == target.numpy())\n",
    "    accuracy = num_correct / count\n",
    "    bar.set_description(\"Loss: {}, Test Acc: {}\".format(avg_loss, accuracy))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    out = hypernetwork(inp=[test_set[i][0].to(hypernetwork.device)], has_aux=False)\n",
    "    _, predicted = torch.max(out.detach(), -1)\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(test_set[i][0].detach().numpy().squeeze(), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Prediction: {}\".format(predicted.item()))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7271dcc4a91420ffb9cc5ce7ff5a5d83d948f729c0ba20dec48f9a748a86390"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit ('jax_gpu': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}