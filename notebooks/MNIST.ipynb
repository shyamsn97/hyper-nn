{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "## load mnist dataset\n",
    "\n",
    "root = 'data'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "\n",
    "trans = transforms.Compose([transforms.ToTensor()])\n",
    "# if not exist, download mnist dataset\n",
    "train_set = torchvision.datasets.MNIST(root=root, train=True, transform=trans, download=True)\n",
    "test_set = torchvision.datasets.MNIST(root=root, train=False, transform=trans, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(train_set[i][0].detach().numpy().squeeze(), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(train_set[i][1]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class TorchMNISTConvNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 512, 3, 2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(512, 512, 3, 2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(512, 512, 3, 2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(512, 10, 2, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x).view(x.size(0), -1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4745226"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_target_network = TorchMNISTConvNet()\n",
    "pytorch_total_params = sum(p.numel() for p in torch_target_network.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_target_network(torch.zeros(1,1,28,28)).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypernn.torch.static_hypernet import TorchHyperNetwork\n",
    "from typing import Any, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Embedding Module + Weight Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating hypernetwork with Class definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypernetwork = TorchHyperNetwork.from_target(\n",
    "    torch_target_network,\n",
    "    embedding_dim=4,\n",
    "    num_embeddings=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecursiveHyperNetwork(TorchHyperNetwork):\n",
    "    def __init__(\n",
    "        self,\n",
    "        target_network: nn.Module,\n",
    "        num_target_parameters: Optional[int] = None,\n",
    "        embedding_dim: int = 100,\n",
    "        num_embeddings: int = 3,\n",
    "        hidden_dim: Optional[int] = None,\n",
    "        *args, **kwargs\n",
    "    ):\n",
    "        super().__init__(\n",
    "                    target_network = target_network,\n",
    "                    num_target_parameters = num_target_parameters,\n",
    "                    embedding_dim = embedding_dim,\n",
    "                    num_embeddings = num_embeddings,\n",
    "                    hidden_dim = hidden_dim,\n",
    "                )\n",
    "\n",
    "    def make_weight_generator(self):\n",
    "        return nn.Linear(self.embedding_dim, self.hidden_dim, bias=False)\n",
    "\n",
    "    def generate_params(\n",
    "        self, inp = []\n",
    "    ) -> Tuple[torch.Tensor, Dict[str, Any]]:\n",
    "        embedding = self.embedding(torch.arange(self.num_embeddings).to(self.device))\n",
    "        generated_params = torch.tanh(self.weight_generator(embedding).view(-1))\n",
    "        return generated_params, {\"embedding\": embedding}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_hyper(num_levels: int, target_network, embedding_dim, num_embeddings):\n",
    "    t = target_network\n",
    "    for i in range(num_levels - 1):\n",
    "        hypernetwork = RecursiveHyperNetwork.from_target(\n",
    "                    t,\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_embeddings=num_embeddings\n",
    "        )\n",
    "        t = hypernetwork\n",
    "    hypernetwork = RecursiveHyperNetwork.from_target(\n",
    "                t,\n",
    "                embedding_dim=4,\n",
    "                num_embeddings=num_embeddings\n",
    "    )\n",
    "    return hypernetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperHyper(nn.Module):\n",
    "    def __init__(self, num_levels, target_network, embedding_dim, num_embeddings):\n",
    "        super().__init__()\n",
    "        self.num_levels = num_levels\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.hypernetwork = hyper_hyper(num_levels, target_network, embedding_dim, num_embeddings)\n",
    "\n",
    "    def forward(self, x):\n",
    "        inp = x.to(self.hypernetwork.device)\n",
    "        for i in range(self.num_levels - 1):\n",
    "                inp = [inp]\n",
    "        return self.hypernetwork(inp=[inp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypernetwork = HyperHyper(5, torch_target_network, 8, 72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in hypernetwork.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0036,  0.0044, -0.0040,  0.0044, -0.0131,  0.0022, -0.0040, -0.0288,\n",
       "          0.0086,  0.0031]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypernetwork(torch.zeros((1,1,28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "hypernetwork = hypernetwork.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=32,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=32,\n",
    "                shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train hypernetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "def get_tensorboard_logger(\n",
    "    experiment_name: str, base_log_path: str = \"tensorboard_logs\"\n",
    "):\n",
    "    log_path = \"{}/{}_{}\".format(base_log_path, experiment_name, datetime.now())\n",
    "    train_writer = SummaryWriter(log_path, flush_secs=10)\n",
    "    full_log_path = os.path.join(os.getcwd(), log_path)\n",
    "    print(\n",
    "        \"Follow tensorboard logs with: python -m tensorboard.main --logdir '{}'\".format(full_log_path)\n",
    "    )\n",
    "    return train_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Follow tensorboard logs with: python -m tensorboard.main --logdir '/home/shyam/Code/hyper-nn/notebooks/tensorboard_logs/HypernetworkTorchRL_2022-04-26 17:06:53.438081'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9432039260864258, Test Acc: 0.6363000273704529: 100%|██████████| 1000/1000 [5:59:45<00:00, 21.59s/it]  \n"
     ]
    }
   ],
   "source": [
    "def random_sample(dataset, num_samples:int = 1):\n",
    "    length = len(dataset)\n",
    "    random_indices = np.random.randint(0,length, num_samples)\n",
    "    return torch.stack([dataset[idx][0] for idx in random_indices]), torch.tensor([dataset[idx][1] for idx in random_indices])\n",
    "\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=32,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=32,\n",
    "                shuffle=False)\n",
    "\n",
    "writer = get_tensorboard_logger(\"HypernetworkTorchRL\")\n",
    "\n",
    "hypernetwork = HyperHyper(5, torch_target_network, 4, 64)\n",
    "\n",
    "optimizer = torch.optim.Adam(hypernetwork.parameters(), lr=0.001)\n",
    "bar = tqdm.tqdm(np.arange(1000))\n",
    "\n",
    "for i in bar:\n",
    "\n",
    "    train_loss = []\n",
    "    x, target = random_sample(train_set, 32)\n",
    "    x = x.to(device)\n",
    "    target = target.to(device)\n",
    "    # for batch_idx, (x, target) in enumerate(train_loader):\n",
    "    # for sample in samples:\n",
    "    optimizer.zero_grad()\n",
    "    inp = x.to(device)\n",
    "    out = hypernetwork(inp)\n",
    "    loss =  torch.nn.functional.cross_entropy(out.to(device), target.to(device))\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(hypernetwork.parameters(), 10.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    train_loss.append(loss.item())\n",
    "\n",
    "    avg_loss = np.mean(train_loss)\n",
    "\n",
    "    grad_dict = {}\n",
    "    for n, W in hypernetwork.named_parameters():\n",
    "        if W.grad is not None:\n",
    "            grad_dict[\"{}_grad\".format(n)] = float(torch.sum(W.grad).item())\n",
    "\n",
    "    metrics = {\"loss\":loss.item(), **grad_dict}\n",
    "\n",
    "    for key in metrics:\n",
    "        writer.add_scalar(key, metrics[key], i)\n",
    "\n",
    "    num_correct = 0\n",
    "    count = 0\n",
    "    for batch_idx, (x, target) in enumerate(test_loader):\n",
    "        count += x.size(0)\n",
    "        with torch.no_grad():\n",
    "            out = hypernetwork(x.to(device))\n",
    "            _, predicted = torch.max(out.detach(), -1)\n",
    "        num_correct += (predicted.detach().cpu() == target.data).sum()\n",
    "    accuracy = num_correct / count\n",
    "\n",
    "    grad_dict = {}\n",
    "    for n, W in hypernetwork.named_parameters():\n",
    "        if W.grad is not None:\n",
    "            grad_dict[\"{}_grad\".format(n)] = float(torch.sum(W.grad).item())\n",
    "\n",
    "    metrics = {\"loss\":loss.item(), \"accuracy\":accuracy.item(), **grad_dict}\n",
    "\n",
    "    for key in metrics:\n",
    "        writer.add_scalar(key, metrics[key], i)\n",
    "\n",
    "    bar.set_description(\"Loss: {}, Test Acc: {}\".format(avg_loss, accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display subset of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    out = hypernetwork(inp=[test_set[i][0].to(hypernetwork.device)], has_aux=False)\n",
    "    _, predicted = torch.max(out.detach(), -1)\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(test_set[i][0].detach().numpy().squeeze(), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Prediction: {}\".format(predicted.item()))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Hypernetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional, Tuple, Type, Union  # noqa\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMHypernetwork(TorchHyperNetwork):\n",
    "    def __init__(\n",
    "        self,\n",
    "        target_network: nn.Module,\n",
    "        num_target_parameters: Optional[int] = None,\n",
    "        embedding_dim: int = 100,\n",
    "        num_embeddings: int = 3,\n",
    "        hidden_dim: Optional[int] = None,\n",
    "        *args, **kwargs\n",
    "    ):\n",
    "        super().__init__(\n",
    "                    target_network = target_network,\n",
    "                    num_target_parameters = num_target_parameters,\n",
    "                    embedding_dim = embedding_dim,\n",
    "                    num_embeddings = num_embeddings,\n",
    "                    hidden_dim = hidden_dim,\n",
    "                )\n",
    "\n",
    "    def make_embedding(self):\n",
    "        embedding = nn.Parameter(torch.randn(1, self.embedding_dim).to(self.device))\n",
    "        return embedding\n",
    "\n",
    "    def make_weight_generator(self):\n",
    "        return nn.GRUCell(self.embedding_dim, self.hidden_dim)\n",
    "\n",
    "    def generate_params(\n",
    "        self, inp = []\n",
    "    ) -> Tuple[torch.Tensor, Dict[str, Any]]:\n",
    "        embedding = self.embedding\n",
    "        hidden = torch.zeros(1, self.hidden_dim, device=self.device)\n",
    "        output = []\n",
    "        for _ in range(self.num_embeddings):\n",
    "            hidden = self.weight_generator(embedding, hidden)\n",
    "            output.append(hidden)\n",
    "        return torch.stack(output).view(-1), {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypernetwork = LSTMHypernetwork.from_target(\n",
    "    torch_target_network,\n",
    "    embedding_dim=8,\n",
    "    num_embeddings=7000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in hypernetwork.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0585, -0.3283,  0.7292, -0.5671, -0.0905, -0.7228, -0.0016, -0.0040,\n",
       "         -0.3661,  0.2521]], device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypernetwork(inp=[torch.zeros((1,1,28,28), device=hypernetwork.device)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "hypernetwork = hypernetwork.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([67, 74, 83, 90, 54])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0,100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sample(dataset, num_samples:int = 1):\n",
    "    length = len(dataset)\n",
    "    random_indices = np.random.randint(0,length, num_samples)\n",
    "    return [dataset[idx] for idx in random_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.03393292427063, Test Acc: 0.10329999774694443:   0%|          | 1/1000 [01:34<26:19:02, 94.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2978427410125732, Test Acc: 0.10320000350475311:   0%|          | 2/1000 [03:08<26:02:35, 93.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2978427410125732, Test Acc: 0.10320000350475311:   0%|          | 2/1000 [03:43<31:00:24, 111.85s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_90591/903286999.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhypernetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypernetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mnum_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycanvas/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycanvas/lib/python3.9/site-packages/hypernn-0.1.0-py3.9.egg/hypernn/torch/hypernet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, generated_params, has_aux, *args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0maux_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgenerated_params\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mgenerated_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_90591/2128266366.py\u001b[0m in \u001b[0;36mgenerate_params\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycanvas/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pycanvas/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRUCell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_chunks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfactory_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0;34mf\"GRUCell: Expected input to be 1-D or 2-D but received {input.dim()}-D tensor\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "num_samples = 1\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=32,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=32,\n",
    "                shuffle=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(hypernetwork.parameters(), lr=0.001)\n",
    "bar = tqdm.tqdm(np.arange(1000))\n",
    "\n",
    "for i in bar:\n",
    "\n",
    "    train_loss = []\n",
    "    samples = random_sample(train_set, num_samples)\n",
    "    for sample in samples:\n",
    "        x = sample[0].view(1, 1, 28, 28).to(hypernetwork.device)\n",
    "        target = torch.tensor(sample[1]).view(1,).to(hypernetwork.device)\n",
    "        optimizer.zero_grad()\n",
    "        out = hypernetwork(inp=[x.to(hypernetwork.device)], has_aux=False)\n",
    "        loss =  torch.nn.functional.cross_entropy(out.to(hypernetwork.device), target.to(hypernetwork.device))\n",
    "        print(\"SHIT\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "    avg_loss = np.mean(train_loss)\n",
    "    num_correct = 0\n",
    "    count = 0\n",
    "    for batch_idx, (x, target) in enumerate(test_loader):\n",
    "        count += x.size(0)\n",
    "        with torch.no_grad():\n",
    "            out = hypernetwork(inp=[x.to(hypernetwork.device)], has_aux=False)\n",
    "            _, predicted = torch.max(out.detach(), -1)\n",
    "        num_correct += (predicted.detach().cpu() == target.data).sum()\n",
    "    accuracy = num_correct / count\n",
    "    bar.set_description(\"Loss: {}, Test Acc: {}\".format(avg_loss, accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this to enable jax gpu preallocation, might lead to memory issues\n",
    "\n",
    "import os\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax.linen as linen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JaxMNISTConvNet(linen.Module):\n",
    "\n",
    "    @linen.compact\n",
    "    def __call__(self, x):\n",
    "        x = linen.Conv(64, kernel_size=(3,3), strides=2, padding=\"VALID\")(x)\n",
    "        x = linen.relu(x)\n",
    "        x = linen.Conv(64, kernel_size=(3,3), strides=2, padding=\"VALID\")(x)\n",
    "        x = linen.relu(x)\n",
    "        x = linen.Conv(64, kernel_size=(3,3), strides=2, padding=\"VALID\")(x)\n",
    "        x = linen.relu(x)\n",
    "        x = linen.Conv(10, kernel_size=(2,2), strides=2, padding=\"VALID\")(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = linen.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax_target_network = JaxMNISTConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypernn.jax.utils import count_jax_params\n",
    "\n",
    "count_jax_params(jax_target_network, inputs=[jnp.zeros((64,64,1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Jax Hypernetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Any, Dict\n",
    "\n",
    "from hypernn.jax.embedding_module import FlaxEmbeddingModule\n",
    "from hypernn.jax.weight_generator import FlaxWeightGenerator\n",
    "from hypernn.jax.hypernet import FlaxHyperNetwork\n",
    "\n",
    "\n",
    "class CustomFlaxEmbeddingModule(FlaxEmbeddingModule):\n",
    "    def setup(self):\n",
    "        self.embedding = linen.Embed(self.num_embeddings, self.embedding_dim)\n",
    "\n",
    "    def __call__(self, inp: Optional[Any] = None):\n",
    "        indices = jnp.arange(0, self.num_embeddings)\n",
    "        return self.embedding(indices), {}\n",
    "\n",
    "class CustomFlaxWeightGenerator(FlaxWeightGenerator):\n",
    "    def setup(self):\n",
    "        self.dense1 = linen.Dense(32)\n",
    "        self.dense2 = linen.Dense(self.hidden_dim, use_bias=False)\n",
    "\n",
    "    def __call__(self, embedding, inp: Optional[Any] = None):\n",
    "        x = self.dense1(embedding)\n",
    "        x = linen.tanh(x)\n",
    "        x = self.dense2(x)\n",
    "        return x.reshape(-1), {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making hypernetwork with `embedding_dim = 4` and `num_embeddings = 1024`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax_hyper = FlaxHyperNetwork.from_target(\n",
    "    target_network=jax_target_network,\n",
    "    inputs=[jnp.zeros((28,28,1))],\n",
    "    embedding_module=CustomFlaxEmbeddingModule,\n",
    "    weight_generator=CustomFlaxWeightGenerator,\n",
    "    embedding_dim = 4,\n",
    "    num_embeddings = 1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_jax_params(jax_hyper, inputs=[[jnp.zeros((28,28,1))]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating train state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "from flax.training import train_state  # Useful dataclass to keep train state\n",
    "\n",
    "def create_hyper_train_state(rng, model, learning_rate):\n",
    "    \"\"\"Creates initial `TrainState`.\"\"\"\n",
    "    params = model.init(rng, [jnp.zeros((28,28,1))])['params']\n",
    "    tx = optax.chain(\n",
    "        optax.adam(learning_rate)\n",
    "    )\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=model.apply, params=params, tx=tx\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(logits, labels):\n",
    "    one_hot_labels = jax.nn.one_hot(labels, num_classes=10)\n",
    "    return -jnp.mean(jnp.sum(one_hot_labels * logits, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "@jax.jit\n",
    "def compute_metrics(logits, labels):\n",
    "    loss = cross_entropy_loss(logits=logits, labels=labels)\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "    metrics = {\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=('apply_fn'))\n",
    "def train_step(apply_fn, state, x, targets):\n",
    "    \"\"\"Train for a single step.\"\"\"\n",
    "    def loss_fn(params):\n",
    "        logits = apply_fn({'params': params}, inp=[x], has_aux=False)\n",
    "        loss = cross_entropy_loss(logits=logits, labels=targets)\n",
    "        return loss, logits\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (_, logits), grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    metrics = compute_metrics(logits=logits, labels=targets)\n",
    "    return state, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "\n",
    "bar = tqdm.tqdm(np.arange(1000))\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "state = create_hyper_train_state(rng, jax_hyper, 0.0002)\n",
    "\n",
    "for i in bar:\n",
    "\n",
    "    train_loss = []\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        x = rearrange(jnp.array(x.numpy()), 'b c w h -> b w h c')\n",
    "        target = jnp.array(target.numpy())\n",
    "\n",
    "        state, metrics = train_step(jax_hyper.apply, state, x, target)\n",
    "        loss = metrics[\"loss\"]\n",
    "        # optimizer.zero_grad()\n",
    "        # out = hypernetwork(inp=[x.to(hypernetwork.device)], has_aux=False)\n",
    "        # loss =  torch.nn.functional.cross_entropy(out.to(hypernetwork.device), target.to(hypernetwork.device))\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "    avg_loss = np.mean(train_loss)\n",
    "    num_correct = 0\n",
    "    count = 0\n",
    "    for batch_idx, (x, target) in enumerate(test_loader):\n",
    "        x = rearrange(jnp.array(x.numpy()), 'b c w h -> b w h c')\n",
    "        count += x.shape[0]\n",
    "        logits = jax_hyper.apply({\"params\":state.params}, inp=[x], has_aux=False)\n",
    "        # with torch.no_grad():\n",
    "        #     out = hypernetwork(inp=[x.to(hypernetwork.device)], has_aux=False)\n",
    "        #     _, predicted = torch.max(out.detach(), -1)\n",
    "        num_correct += jnp.sum(jnp.argmax(logits, -1) == target.numpy())\n",
    "    accuracy = num_correct / count\n",
    "    bar.set_description(\"Loss: {}, Test Acc: {}\".format(avg_loss, accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    out = hypernetwork(inp=[test_set[i][0].to(hypernetwork.device)], has_aux=False)\n",
    "    _, predicted = torch.max(out.detach(), -1)\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(test_set[i][0].detach().numpy().squeeze(), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Prediction: {}\".format(predicted.item()))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d64cb66d3d902aa83000daa06ca958bef94bde318911a82aee5f8df2bb8934b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
